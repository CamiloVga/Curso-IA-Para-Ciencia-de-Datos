{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXfyz3w7PQn62LNdpEpRhM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CamiloVga/Curso-IA-Para-Ciencia-de-Datos/blob/main/Script_Sesi%C3%B3n_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IA para la Ciencia de Datos\n",
        "## Universidad de los Andes\n",
        "\n",
        "**Profesor:** Camilo Vega - AI/ML Engineer  \n",
        "**LinkedIn:** https://www.linkedin.com/in/camilo-vega-169084b1/\n",
        "\n",
        "---\n",
        "\n",
        "## Gu√≠a: Sistemas de Agentes Inteligentes y Multi-Agente con LLM\n",
        "\n",
        "Este notebook presenta **3 implementaciones pr√°cticas**:\n",
        "\n",
        "1. **RAG Agent con Langchain + OpenAI** - Agente inteligente que busca en documentos locales\n",
        "2. **Deep Research Agent con Groq + Tavily** - Investigaci√≥n web con trazabilidad de fuentes\n",
        "3. **Sistema Multi-Agente con CrewAI** - Flujo editorial completo (4 agentes especializados)\n",
        "\n",
        "### Arquitecturas de Agentes\n",
        "- **Agente Simple:** Un LLM + herramientas espec√≠ficas + prompt estructurado\n",
        "- **Agente de Investigaci√≥n:** LLM + b√∫squeda web + gesti√≥n de fuentes\n",
        "- **Multi-Agente:** M√∫ltiples LLMs especializados trabajando en pipeline colaborativo\n",
        "\n",
        "### Requisitos\n",
        "- **APIs Principales:**\n",
        "  - OpenAI API token (GPT-4o, GPT-4o-mini)\n",
        "  - Groq API token (Llama, Mixtral, otros)\n",
        "  - Tavily API token (b√∫squeda web especializada)\n",
        "- **GPU:** No requerida (uso de APIs)\n",
        "- **Datos:** Documentos PDF para RAG local (carpeta `/content/carpeta_rag`)\n",
        "\n",
        "## Configuraci√≥n APIs\n",
        "- **OpenAI API:**\n",
        "  1. [Crear token](https://platform.openai.com/api-keys)\n",
        "  2. En Colab: üîë Secrets ‚Üí Agregar `OPENAI_API_KEY` ‚Üí Pegar tu token\n",
        "\n",
        "- **Groq API:**\n",
        "  1. [Crear token](https://console.groq.com/keys)\n",
        "  2. En Colab: üîë Secrets ‚Üí Agregar `GROQ_KEY` ‚Üí Pegar tu token\n",
        "\n",
        "- **Tavily API:**\n",
        "  1. [Crear token](https://tavily.com)\n",
        "  2. En Colab: üîë Secrets ‚Üí Agregar `TAVILY_KEY` ‚Üí Pegar tu token\n",
        "\n",
        "### Frameworks y Librer√≠as\n",
        "- **LangChain:** Orquestaci√≥n de agentes y herramientas\n",
        "- **CrewAI:** Sistema multi-agente con roles y tareas espec√≠ficas\n",
        "- **ChromaDB:** Base de datos vectorial para RAG\n",
        "- **Tavily:** API de b√∫squeda web optimizada para IA\n",
        "\n",
        "### Casos de Uso Implementados\n",
        "1. **Consultor de Documentos:** RAG que responde preguntas sobre archivos PDF locales\n",
        "2. **Investigador Digital:** B√∫squeda web inteligente con referencias y fuentes\n",
        "3. **Redacci√≥n Editorial:** 4 agentes (Investigador + Redactor + Editor + Community Manager) trabajando en pipeline\n",
        "\n",
        "Cada secci√≥n es **independiente** y puede ejecutarse por separado. Los agentes pueden configurarse con diferentes modelos de LLM seg√∫n necesidades de velocidad vs. calidad."
      ],
      "metadata": {
        "id": "FeVvbsadjuq_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Agente RAG-Langchain"
      ],
      "metadata": {
        "id": "twihxN5zjygq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#RAG Langchain + OpenAI\n",
        "\n",
        "# 0. Instalaciones\n",
        "!pip install langchain langchain-openai langchain-community chromadb pypdf\n",
        "\n",
        "# 1. Imports\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain.tools import Tool\n",
        "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "# 2. Configuraci√≥n API\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# 3. Crear herramienta RAG\n",
        "def create_rag_search():\n",
        "    # Cargar documentos\n",
        "    loader = DirectoryLoader(\"/content/carpeta_rag\", glob=\"**/*.pdf\", loader_cls=PyPDFLoader) #Crear carpeta en el directorio llamada carpeta_rag y subir los PDF a analizar\n",
        "    docs = loader.load()\n",
        "\n",
        "    # Dividir en chunks\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    splits = splitter.split_documents(docs)\n",
        "\n",
        "    # Crear vectorstore\n",
        "    vectorstore = Chroma.from_documents(splits, OpenAIEmbeddings())\n",
        "    retriever = vectorstore.as_retriever()\n",
        "\n",
        "    # Funci√≥n de b√∫squeda\n",
        "    def search_docs(query: str) -> str:\n",
        "        docs = retriever.get_relevant_documents(query)\n",
        "        return \"\\n\".join([doc.page_content for doc in docs[:2]])\n",
        "\n",
        "    return Tool(\n",
        "        name=\"search_documents\",\n",
        "        description=\"Busca informaci√≥n en los documentos locales\",\n",
        "        func=search_docs\n",
        "    )\n",
        "\n",
        "# 4. Configurar herramientas disponibles\n",
        "rag_search = create_rag_search()\n",
        "tools = [rag_search]\n",
        "\n",
        "# 5. Crear prompt template\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful research assistant\"),\n",
        "    (\"human\", \"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
        "])\n",
        "\n",
        "# 6. Crear agente con herramientas\n",
        "agent = create_openai_functions_agent(\n",
        "    llm=ChatOpenAI(),\n",
        "    tools=tools,\n",
        "    prompt=prompt\n",
        ")\n",
        "\n",
        "# 7. Ejecutor del agente\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True) # Dejar verbose=False para que no muestre el proceso interno del agente para responder\n",
        "\n",
        "# 8. Ejemplo de uso\n",
        "response = agent_executor.invoke({\"input\": \"¬øDe qu√© tratan los documentos?\"})\n",
        "print(response['output'])"
      ],
      "metadata": {
        "id": "XC-QHhQld7Rm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Agente DeepResearch (Internet)-Langchain"
      ],
      "metadata": {
        "id": "13r7LWLZj4Ii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deep Research Agent + OpenAI\n",
        "\n",
        "# 0. Instalaciones\n",
        "!pip install langchain langchain-openai tavily-python\n",
        "\n",
        "# 1. Imports\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.tools import Tool\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from tavily import TavilyClient\n",
        "\n",
        "# 2. Configuraci√≥n API\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "tavily_client = TavilyClient(api_key=userdata.get('TAVILY_KEY'))\n",
        "\n",
        "# Configuraci√≥n OpenAI\n",
        "OPENAI_MODEL = \"gpt-4o\"  # Cambiar por: \"gpt-4o\", \"gpt-4-turbo\", \"gpt-3.5-turbo\"\n",
        "TEMPERATURE = 0.1        # Creatividad (0.0=determinista, 1.0=creativo)\n",
        "\n",
        "# Configuraci√≥n Tavily\n",
        "MAX_RESULTS = 5          # N√∫mero de resultados por b√∫squeda (1-20)\n",
        "TOPIC = \"general\"        # Tipo: \"general\", \"news\", \"finance\"\n",
        "# TIME_RANGE = \"day\"     # Tiempo: \"day\", \"week\", \"month\", \"year\"\n",
        "# LANGUAGE = \"es\"        # Idioma preferido\n",
        "# LOCATION = \"CO\"        # C√≥digo de pa√≠s (CO=Colombia)\n",
        "# INCLUDE_ANSWER = \"basic\"  # Respuesta: \"basic\", \"advanced\"\n",
        "# INCLUDE_RAW_CONTENT = False  # True para contenido completo\n",
        "# INCLUDE_DOMAINS = [\"ejemplo.com\"]  # Dominios espec√≠ficos\n",
        "# EXCLUDE_DOMAINS = [\"spam.com\"]     # Excluir dominios\n",
        "\n",
        "# 3. Crear herramienta de investigaci√≥n web\n",
        "def create_web_search():\n",
        "    def search_web(query: str) -> str:\n",
        "        \"\"\"Busca informaci√≥n actualizada en la web\"\"\"\n",
        "        try:\n",
        "            # Configuraci√≥n b√°sica de b√∫squeda\n",
        "            search_params = {\n",
        "                \"query\": query,\n",
        "                \"max_results\": MAX_RESULTS,\n",
        "                \"topic\": TOPIC\n",
        "            }\n",
        "\n",
        "            # Agregar par√°metros opcionales (descomenta seg√∫n necesites)\n",
        "            # if TIME_RANGE: search_params[\"time_range\"] = TIME_RANGE\n",
        "            # if LANGUAGE: search_params[\"language\"] = LANGUAGE\n",
        "            # if LOCATION: search_params[\"location\"] = LOCATION\n",
        "            # if INCLUDE_ANSWER: search_params[\"include_answer\"] = INCLUDE_ANSWER\n",
        "            # if INCLUDE_RAW_CONTENT: search_params[\"include_raw_content\"] = INCLUDE_RAW_CONTENT\n",
        "            # if INCLUDE_DOMAINS: search_params[\"include_domains\"] = INCLUDE_DOMAINS\n",
        "            # if EXCLUDE_DOMAINS: search_params[\"exclude_domains\"] = EXCLUDE_DOMAINS\n",
        "\n",
        "            response = tavily_client.search(**search_params)\n",
        "\n",
        "            # Extraer contenido relevante\n",
        "            results = []\n",
        "            for result in response.get(\"results\", []):\n",
        "                title = result.get('title', 'Sin t√≠tulo')\n",
        "                content = result.get('content', '')[:500]\n",
        "                results.append(f\"**{title}**\\n{content}...\")\n",
        "\n",
        "            return \"\\n\\n\".join(results) if results else \"No se encontr√≥ informaci√≥n relevante.\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error en b√∫squeda web: {e}\"\n",
        "\n",
        "    return Tool(\n",
        "        name=\"web_search\",\n",
        "        description=\"Busca informaci√≥n actualizada en la web sobre cualquier tema\",\n",
        "        func=search_web\n",
        "    )\n",
        "\n",
        "# 4. Configurar herramientas disponibles\n",
        "web_search = create_web_search()\n",
        "tools = [web_search]\n",
        "\n",
        "# 5. Crear prompt template\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"Eres un investigador experto que analiza informaci√≥n y responde de manera clara y detallada. Siempre usa la herramienta de b√∫squeda web para obtener informaci√≥n actualizada.\"),\n",
        "    (\"human\", \"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
        "])\n",
        "\n",
        "# 6. Crear agente con herramientas\n",
        "agent = create_openai_functions_agent(\n",
        "    llm=ChatOpenAI(model=OPENAI_MODEL, temperature=TEMPERATURE),\n",
        "    tools=tools,\n",
        "    prompt=prompt\n",
        ")\n",
        "\n",
        "# 7. Ejecutor del agente\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True) # Dejar verbose=False para que no muestre el proceso interno del agente para responder\n",
        "\n",
        "# 8. Ejemplo de uso\n",
        "response = agent_executor.invoke({\"input\": \"¬øQui√©n es Camilo Vega Barbosa?\"})\n",
        "print(response['output'])"
      ],
      "metadata": {
        "id": "_Va7U9NpfhLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Agente DeepResearch (Internet)-Groq"
      ],
      "metadata": {
        "id": "zJ8jQ4unj_ND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deep Research Agent con Groq y Trazabilidad de Fuentes\n",
        "\n",
        "# 1. Instalaciones\n",
        "!pip install groq tavily-python\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from tavily import TavilyClient\n",
        "from groq import Groq\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "# 2. CONFIGURACI√ìN\n",
        "\n",
        "# Configuraci√≥n Groq\n",
        "GROQ_MODEL = \"openai/gpt-oss-20b\"        # Modelo de lenguaje a usar\n",
        "MAX_TOKENS = 1024                        # M√°ximo tokens en respuesta (512-8192)\n",
        "TEMPERATURE = 0.1                        # Creatividad (0.0=determinista, 1.0=creativo)\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"Eres un investigador experto. Analiza la informaci√≥n y responde de manera clara, detallada y objetiva.\n",
        "IMPORTANTE: Incluye referencias [1], [2], etc. para cada informaci√≥n espec√≠fica que uses. Ademas prioriza la informaci√≥n m√°s reciente que provenga de medios o fuentes confiables del lugar o del tema\"\"\"\n",
        "\n",
        "# Configuraci√≥n Tavily\n",
        "MAX_RESULTS = 5                          # Resultados por b√∫squeda (1-20)\n",
        "TAVILY_TOPIC = \"general\"                 # Tipo: \"general\", \"news\", \"finance\"\n",
        "TAVILY_TIME_RANGE = None                 # Tiempo: \"day\", \"week\", \"month\", \"year\"\n",
        "TAVILY_INCLUDE_ANSWER = \"basic\"          # Respuesta: \"basic\", \"advanced\"\n",
        "TAVILY_INCLUDE_RAW_CONTENT = False       # True para contenido completo\n",
        "TAVILY_INCLUDE_DOMAINS = None            # [\"ejemplo.com\"] para dominios espec√≠ficos\n",
        "TAVILY_EXCLUDE_DOMAINS = None            # [\"spam.com\"] para excluir dominios\n",
        "TAVILY_LOCATION = \"CO\"                   # C√≥digo de pa√≠s (CO=Colombia)\n",
        "TAVILY_LANGUAGE = \"es\"                   # Idioma preferido\n",
        "\n",
        "# Configuraci√≥n investigaci√≥n\n",
        "MAX_ADDITIONAL_SEARCHES = 2              # B√∫squedas adicionales m√°ximas\n",
        "ADDITIONAL_RESULTS = 3                   # Resultados por b√∫squeda adicional\n",
        "MAX_CONTENT_CHARS = 800                  # Caracteres por fuente\n",
        "\n",
        "# 3. INICIALIZACI√ìN\n",
        "groq_client = Groq(api_key=userdata.get('GROQ_KEY'))\n",
        "tavily = TavilyClient(api_key=userdata.get('TAVILY_KEY'))\n",
        "print(\"‚úÖ Clientes inicializados\")\n",
        "\n",
        "# 4. SISTEMA DE TRAZABILIDAD Y FUNCIONES PRINCIPALES\n",
        "\n",
        "class SimpleTracker:\n",
        "    \"\"\"Gestiona el registro y formato de fuentes consultadas\"\"\"\n",
        "    def __init__(self):\n",
        "        self.sources = []\n",
        "        self.counter = 0\n",
        "\n",
        "    def add(self, title, url, content):\n",
        "        \"\"\"Registra una nueva fuente y retorna su ID de referencia\"\"\"\n",
        "        self.counter += 1\n",
        "        self.sources.append({\n",
        "            'id': self.counter, 'title': title, 'url': url,\n",
        "            'content': content[:200] + \"...\" if len(content) > 200 else content,\n",
        "            'domain': urlparse(url).netloc if url else \"Unknown\"\n",
        "        })\n",
        "        return self.counter\n",
        "\n",
        "    def format_sources(self):\n",
        "        \"\"\"Genera el formato final de fuentes para el reporte\"\"\"\n",
        "        if not self.sources:\n",
        "            return \"No hay fuentes.\"\n",
        "\n",
        "        result = f\"\\n## üìö FUENTES ({len(self.sources)} consultadas)\\n\\n\"\n",
        "        domains = {}\n",
        "\n",
        "        for s in self.sources:\n",
        "            result += f\"**[{s['id']}]** {s['title']}\\nüîó {s['url']}\\nüìÑ {s['content']}\\n\\n\"\n",
        "            domains[s['domain']] = domains.get(s['domain'], 0) + 1\n",
        "\n",
        "        result += \"**Dominios:** \" + \", \".join([f\"{d}({c})\" for d, c in domains.items()])\n",
        "        return result\n",
        "\n",
        "def buscar(query, tracker, max_results=MAX_RESULTS):\n",
        "    \"\"\"B√∫squeda web con configuraci√≥n completa y registro de fuentes\"\"\"\n",
        "    try:\n",
        "        # Configurar par√°metros de b√∫squeda\n",
        "        search_params = {\n",
        "            \"query\": query,\n",
        "            \"max_results\": max_results,\n",
        "            \"topic\": TAVILY_TOPIC\n",
        "        }\n",
        "\n",
        "        # Agregar par√°metros opcionales\n",
        "        if TAVILY_TIME_RANGE:\n",
        "            search_params[\"time_range\"] = TAVILY_TIME_RANGE\n",
        "        if TAVILY_INCLUDE_ANSWER:\n",
        "            search_params[\"include_answer\"] = TAVILY_INCLUDE_ANSWER\n",
        "        if TAVILY_INCLUDE_RAW_CONTENT:\n",
        "            search_params[\"include_raw_content\"] = TAVILY_INCLUDE_RAW_CONTENT\n",
        "        if TAVILY_INCLUDE_DOMAINS:\n",
        "            search_params[\"include_domains\"] = TAVILY_INCLUDE_DOMAINS\n",
        "        if TAVILY_EXCLUDE_DOMAINS:\n",
        "            search_params[\"exclude_domains\"] = TAVILY_EXCLUDE_DOMAINS\n",
        "        if TAVILY_LOCATION:\n",
        "            search_params[\"location\"] = TAVILY_LOCATION\n",
        "        if TAVILY_LANGUAGE:\n",
        "            search_params[\"language\"] = TAVILY_LANGUAGE\n",
        "\n",
        "        response = tavily.search(**search_params)\n",
        "        content = \"\"\n",
        "\n",
        "        for r in response.get(\"results\", []):\n",
        "            source_id = tracker.add(\n",
        "                r.get('title', 'Sin t√≠tulo'),\n",
        "                r.get('url', ''),\n",
        "                r.get('content', '')\n",
        "            )\n",
        "            content += f\"**[{source_id}] {r.get('title', '')}**\\n\"\n",
        "            content += f\"{r.get('content', '')[:MAX_CONTENT_CHARS]}...\\n\\n\"\n",
        "\n",
        "        return content\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "def generar(prompt):\n",
        "    \"\"\"Generaci√≥n de an√°lisis usando Groq\"\"\"\n",
        "    try:\n",
        "        response = groq_client.chat.completions.create(\n",
        "            model=GROQ_MODEL,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_tokens=MAX_TOKENS,\n",
        "            temperature=TEMPERATURE\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "def investigar(tema, busquedas_extra=None):\n",
        "    \"\"\"Investigaci√≥n completa con m√∫ltiples b√∫squedas y trazabilidad\"\"\"\n",
        "    print(f\"üîç Investigando: {tema}\")\n",
        "    tracker = SimpleTracker()\n",
        "\n",
        "    # B√∫squeda principal\n",
        "    info = buscar(tema, tracker)\n",
        "\n",
        "    # B√∫squedas adicionales\n",
        "    if busquedas_extra:\n",
        "        for query in busquedas_extra[:MAX_ADDITIONAL_SEARCHES]:\n",
        "            print(f\"üì° B√∫squeda adicional: {query}\")\n",
        "            info += f\"\\n--- {query} ---\\n\" + buscar(query, tracker, ADDITIONAL_RESULTS)\n",
        "\n",
        "    # Generar reporte\n",
        "    print(\"ü§ñ Generando an√°lisis...\")\n",
        "    prompt = f\"\"\"Analiza la siguiente informaci√≥n sobre: {tema}\n",
        "\n",
        "Estructura tu respuesta con:\n",
        "1. Resumen ejecutivo\n",
        "2. Hallazgos clave\n",
        "3. An√°lisis y tendencias\n",
        "4. Conclusiones\n",
        "\n",
        "Incluye referencias [1], [2], etc. para informaci√≥n espec√≠fica.\n",
        "\n",
        "INFORMACI√ìN:\n",
        "{info}\"\"\"\n",
        "\n",
        "    response = generar(prompt)\n",
        "\n",
        "    # Reporte final\n",
        "    return f\"# üìã {tema.upper()}\\n\\n{response}\\n\\n{'='*60}\\n{tracker.format_sources()}\"\n",
        "\n",
        "# 5. USO SIMPLE\n",
        "\n",
        "# Investigaci√≥n en 1-2 l√≠neas:\n",
        "reporte = investigar(\"¬øQui√©n es Camilo Vega Barbosa?\")\n",
        "print(reporte)"
      ],
      "metadata": {
        "id": "igBdIRPpgTAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sistema MultiAgente-CrewAI"
      ],
      "metadata": {
        "id": "JVEZLzcYkFna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Sistema MultiAgente con CrewAI-Flujo de trabajo de equipo en un peri√≥dico\n",
        "\n",
        "# Instalaciones necesarias\n",
        "!pip install crewai tavily-python openai langchain-openai\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from tavily import TavilyClient\n",
        "from openai import OpenAI\n",
        "from crewai import Agent, Task, Crew\n",
        "from crewai.tools import tool\n",
        "from langchain_openai import ChatOpenAI\n",
        "from urllib.parse import urlparse\n",
        "import re\n",
        "\n",
        "# =============================================================================\n",
        "# CONFIGURACI√ìN GLOBAL\n",
        "# =============================================================================\n",
        "\n",
        "# Configurar OpenAI API Key\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Modelos OpenAI para cada agente (usando ChatGPT-4o-mini)\n",
        "OPENAI_MODELS = {\n",
        "    \"research\": \"gpt-4o-mini\",     # Investigaci√≥n\n",
        "    \"writing\": \"gpt-4o-mini\",      # Escritura\n",
        "    \"editing\": \"gpt-4o-mini\",      # Edici√≥n\n",
        "    \"social\": \"gpt-4o-mini\"        # Social media\n",
        "}\n",
        "\n",
        "# Configuraci√≥n Tavily\n",
        "TAVILY_CONFIG = {\n",
        "    \"max_results\": 5,\n",
        "    \"topic\": \"general\",\n",
        "    \"location\": \"CO\",\n",
        "    \"language\": \"es\",\n",
        "    \"include_answer\": \"basic\"\n",
        "}\n",
        "\n",
        "# =============================================================================\n",
        "# HERRAMIENTAS Y TRACKER\n",
        "# =============================================================================\n",
        "\n",
        "# Variable global para el tracker\n",
        "global_tracker = None\n",
        "\n",
        "class NewsroomTracker:\n",
        "    \"\"\"Gestiona fuentes y referencias\"\"\"\n",
        "    def __init__(self):\n",
        "        self.sources = []\n",
        "        self.counter = 0\n",
        "\n",
        "    def add_source(self, title, url, content, agent_name):\n",
        "        self.counter += 1\n",
        "        self.sources.append({\n",
        "            'id': self.counter,\n",
        "            'title': title,\n",
        "            'url': url,\n",
        "            'content': content[:200] + \"...\" if len(content) > 200 else content,\n",
        "            'domain': urlparse(url).netloc if url else \"Unknown\",\n",
        "            'found_by': agent_name\n",
        "        })\n",
        "        return self.counter\n",
        "\n",
        "    def get_sources_summary(self):\n",
        "        if not self.sources:\n",
        "            return \"Sin fuentes disponibles\"\n",
        "\n",
        "        summary = f\"\\nüìö FUENTES CONSULTADAS ({len(self.sources)})\\n\" + \"=\"*50 + \"\\n\"\n",
        "        for s in self.sources:\n",
        "            summary += f\"[{s['id']}] {s['title']} | {s['domain']}\\n\"\n",
        "            summary += f\"üîó {s['url']}\\n\"\n",
        "            summary += f\"üìÑ {s['content']}\\n\\n\"\n",
        "        return summary\n",
        "\n",
        "@tool(\"search_web\")\n",
        "def search_web_tool(query: str) -> str:\n",
        "    \"\"\"Busca informaci√≥n en web usando Tavily API - LIMITADO A 2 RESULTADOS\"\"\"\n",
        "    global global_tracker\n",
        "    try:\n",
        "        tavily = TavilyClient(api_key=userdata.get('TAVILY_KEY'))\n",
        "\n",
        "        # Forzar expl√≠citamente max_results = 2\n",
        "        search_params = {\n",
        "            \"query\": query,\n",
        "            \"max_results\": 2,  # FORZADO A 2\n",
        "            \"topic\": \"general\",\n",
        "            \"location\": \"CO\",\n",
        "            \"language\": \"es\",\n",
        "            \"include_answer\": \"basic\"\n",
        "        }\n",
        "\n",
        "        print(f\"üîç Ejecutando b√∫squeda con max_results = {search_params['max_results']}\")\n",
        "        response = tavily.search(**search_params)\n",
        "\n",
        "        results = response.get(\"results\", [])\n",
        "        print(f\"‚úÖ B√∫squeda: '{query}' | Resultados obtenidos: {len(results)} | M√°ximo configurado: {search_params['max_results']}\")\n",
        "\n",
        "        content = f\"üîç Resultados para: {query} (m√°x: {search_params['max_results']})\\n\\n\"\n",
        "        for i, result in enumerate(results, 1):\n",
        "            source_id = global_tracker.add_source(\n",
        "                result.get('title', 'Sin t√≠tulo'),\n",
        "                result.get('url', ''),\n",
        "                result.get('content', ''),\n",
        "                'Investigador'\n",
        "            )\n",
        "            content += f\"**[{source_id}] Resultado {i}/{len(results)}: {result.get('title', '')}**\\n\"\n",
        "            content += f\"{result.get('content', '')[:400]}...\\n\\n\"\n",
        "\n",
        "        return content\n",
        "    except Exception as e:\n",
        "        return f\"Error en b√∫squeda: {e}\"\n",
        "\n",
        "# =============================================================================\n",
        "# CONFIGURACI√ìN DE AGENTES\n",
        "# =============================================================================\n",
        "\n",
        "def setup_newsroom_agents():\n",
        "    \"\"\"Configura los 4 agentes especializados con OpenAI\"\"\"\n",
        "\n",
        "    # Configurar LLMs con ChatOpenAI\n",
        "    llms = {}\n",
        "    for role, model in OPENAI_MODELS.items():\n",
        "        llms[role] = ChatOpenAI(\n",
        "            model=model,\n",
        "            temperature=0.1 if role in ['research', 'editing'] else 0.7,\n",
        "            api_key=userdata.get('OPENAI_API_KEY')\n",
        "        )\n",
        "        print(f\"‚úÖ Modelo OpenAI {model} configurado para {role}\")\n",
        "\n",
        "    # 1. AGENTE INVESTIGADOR\n",
        "    research_agent = Agent(\n",
        "        role='Investigador Senior',\n",
        "        goal='Encontrar informaci√≥n completa y verificada sobre cualquier tema',\n",
        "        backstory=\"\"\"Eres un investigador period√≠stico experto con 15 a√±os de experiencia.\n",
        "        Sabes distinguir fuentes confiables de rumores y encontrar informaci√≥n precisa.\n",
        "        Tu especialidad es buscar datos verificados y contexto hist√≥rico relevante.\"\"\",\n",
        "        verbose=True,\n",
        "        allow_delegation=False,\n",
        "        llm=llms['research'],\n",
        "        tools=[search_web_tool]\n",
        "    )\n",
        "\n",
        "    # 2. AGENTE REDACTOR\n",
        "    writing_agent = Agent(\n",
        "        role='Redactor Principal',\n",
        "        goal='Crear art√≠culos period√≠sticos claros, informativos y atractivos',\n",
        "        backstory=\"\"\"Eres un redactor senior especializado en periodismo digital.\n",
        "        Escribes con estilo claro y directo, estructuras informaci√≥n de manera l√≥gica\n",
        "        y siempre incluyes referencias apropiadas a las fuentes consultadas.\"\"\",\n",
        "        verbose=True,\n",
        "        allow_delegation=False,\n",
        "        llm=llms['writing']\n",
        "    )\n",
        "\n",
        "    # 3. AGENTE EDITOR\n",
        "    editing_agent = Agent(\n",
        "        role='Editor Jefe',\n",
        "        goal='Revisar y mejorar la calidad editorial del contenido',\n",
        "        backstory=\"\"\"Eres el editor jefe con 20 a√±os de experiencia en medios digitales.\n",
        "        Tu ojo cr√≠tico detecta inconsistencias, errores factuales y problemas de estilo.\n",
        "        Garantizas que cada publicaci√≥n cumpla los est√°ndares editoriales m√°s altos.\"\"\",\n",
        "        verbose=True,\n",
        "        allow_delegation=False,\n",
        "        llm=llms['editing']\n",
        "    )\n",
        "\n",
        "    # 4. AGENTE REDES SOCIALES\n",
        "    social_agent = Agent(\n",
        "        role='Community Manager',\n",
        "        goal='Crear contenido viral y engaging para redes sociales',\n",
        "        backstory=\"\"\"Eres especialista en redes sociales que entiende las tendencias digitales.\n",
        "        Sabes crear hooks atractivos, usar hashtags estrat√©gicos y adaptar mensajes\n",
        "        para cada plataforma. Tu contenido genera engagement y conversaci√≥n.\"\"\",\n",
        "        verbose=True,\n",
        "        allow_delegation=False,\n",
        "        llm=llms['social']\n",
        "    )\n",
        "\n",
        "    return research_agent, writing_agent, editing_agent, social_agent\n",
        "\n",
        "# =============================================================================\n",
        "# DEFINICI√ìN DE TAREAS\n",
        "# =============================================================================\n",
        "\n",
        "def create_newsroom_tasks(agents, topic):\n",
        "    \"\"\"Crea las tareas para el flujo de trabajo\"\"\"\n",
        "\n",
        "    research_agent, writing_agent, editing_agent, social_agent = agents\n",
        "\n",
        "    # TAREA 1: INVESTIGACI√ìN PROFUNDA\n",
        "    research_task = Task(\n",
        "        description=f\"\"\"\n",
        "        Investiga a fondo sobre: {topic}\n",
        "\n",
        "        Debes realizar m√∫ltiples b√∫squedas para cubrir:\n",
        "        1. Informaci√≥n b√°sica y contexto general\n",
        "        2. Datos espec√≠ficos y cifras actualizadas\n",
        "        3. Diferentes perspectivas del tema\n",
        "        4. Fuentes oficiales y expertos en el tema\n",
        "        5. Contexto hist√≥rico si es relevante\n",
        "\n",
        "        Para cada b√∫squeda, analiza los resultados y extrae:\n",
        "        - Informaci√≥n clave con referencias [1], [2], etc.\n",
        "        - Datos verificables y fechas importantes\n",
        "        - Diferentes puntos de vista\n",
        "        - Fuentes primarias cuando sea posible\n",
        "\n",
        "        Entrega un informe estructurado con:\n",
        "        - Resumen ejecutivo (2-3 p√°rrafos)\n",
        "        - Hallazgos principales organizados por temas\n",
        "        - Referencias numeradas a todas las fuentes\n",
        "        - Conclusiones preliminares\n",
        "        \"\"\",\n",
        "        agent=research_agent,\n",
        "        expected_output=\"Informe de investigaci√≥n detallado con m√∫ltiples fuentes verificadas\"\n",
        "    )\n",
        "\n",
        "    # TAREA 2: REDACCI√ìN DEL ART√çCULO\n",
        "    writing_task = Task(\n",
        "        description=f\"\"\"\n",
        "        Bas√°ndote en la investigaci√≥n completa, redacta un art√≠culo period√≠stico profesional sobre: {topic}\n",
        "\n",
        "        El art√≠culo debe incluir:\n",
        "\n",
        "        1. **TITULAR**: Atractivo, preciso y que capte la atenci√≥n\n",
        "        2. **LEAD** (primer p√°rrafo): Responde las 5W - qu√©, qui√©n, cu√°ndo, d√≥nde, por qu√©\n",
        "        3. **DESARROLLO**:\n",
        "           - Estructura de pir√°mide invertida (informaci√≥n m√°s importante primero)\n",
        "           - Subt√≠tulos para facilitar la lectura\n",
        "           - P√°rrafos cortos (m√°ximo 3 l√≠neas cada uno)\n",
        "           - Citas y referencias numeradas [1], [2], etc.\n",
        "        4. **CONCLUSI√ìN**: Resumen de puntos clave y perspectivas futuras\n",
        "\n",
        "        **Estilo period√≠stico:**\n",
        "        - Lenguaje claro, directo y objetivo\n",
        "        - Voz activa\n",
        "        - Informaci√≥n verificable y atribuida\n",
        "        - Tono profesional pero accesible\n",
        "        - Transiciones fluidas entre p√°rrafos\n",
        "\n",
        "        **Extensi√≥n**: 600-900 palabras\n",
        "        **Referencias**: Incluir todas las fuentes como [1], [2], etc.\n",
        "        \"\"\",\n",
        "        agent=writing_agent,\n",
        "        expected_output=\"Art√≠culo period√≠stico completo y bien estructurado\",\n",
        "        context=[research_task]\n",
        "    )\n",
        "\n",
        "    # TAREA 3: EDICI√ìN Y CORRECCI√ìN\n",
        "    editing_task = Task(\n",
        "        description=f\"\"\"\n",
        "        Revisa meticulosamente y mejora el art√≠culo sobre: {topic}\n",
        "\n",
        "        **VERIFICACI√ìN EDITORIAL:**\n",
        "        1. **Precisi√≥n factual**: Confirma datos, fechas y cifras\n",
        "        2. **Gram√°tica y ortograf√≠a**: Correcci√≥n completa\n",
        "        3. **Estilo y claridad**: Mejora la fluidez del texto\n",
        "        4. **Estructura**: Verifica l√≥gica y coherencia\n",
        "        5. **Referencias**: Asegura uso correcto de fuentes [1], [2], etc.\n",
        "        6. **Est√°ndares editoriales**: Cumplimiento de normas period√≠sticas\n",
        "\n",
        "        **MEJORAS A IMPLEMENTAR:**\n",
        "        - Fortalece el titular si es necesario\n",
        "        - Mejora las transiciones entre p√°rrafos\n",
        "        - Optimiza la claridad de las ideas\n",
        "        - Verifica que el lead responda todas las 5W\n",
        "        - Asegura balance entre informaci√≥n y legibilidad\n",
        "\n",
        "        **ENTREGA:**\n",
        "        1. Art√≠culo final editado y corregido\n",
        "        2. Lista detallada de todos los cambios realizados\n",
        "        3. Justificaci√≥n de las mejoras implementadas\n",
        "        4. Recomendaciones adicionales si las hay\n",
        "        \"\"\",\n",
        "        agent=editing_agent,\n",
        "        expected_output=\"Art√≠culo final editado + lista completa de mejoras implementadas\",\n",
        "        context=[writing_task]\n",
        "    )\n",
        "\n",
        "    # TAREA 4: CONTENIDO PARA REDES SOCIALES\n",
        "    social_task = Task(\n",
        "        description=f\"\"\"\n",
        "        Crea una estrategia completa de contenido para redes sociales basada en el art√≠culo sobre: {topic}\n",
        "\n",
        "        **CONTENIDO A GENERAR:**\n",
        "\n",
        "        1. **TWITTER/X** (3 tweets diferentes):\n",
        "           - Tweet 1: Hook + dato impactante (max 280 caracteres)\n",
        "           - Tweet 2: Perspectiva diferente + pregunta (max 280 caracteres)\n",
        "           - Tweet 3: Call-to-action + enlace (max 280 caracteres)\n",
        "\n",
        "        2. **FACEBOOK**:\n",
        "           - Post engaging con pregunta para generar interacci√≥n\n",
        "           - Incluye emoji relevante y call-to-action\n",
        "           - 100-150 palabras\n",
        "\n",
        "        3. **LINKEDIN**:\n",
        "           - Post profesional con insights clave\n",
        "           - Enfoque en implicaciones business/profesionales\n",
        "           - 150-200 palabras\n",
        "\n",
        "        4. **INSTAGRAM STORIES**:\n",
        "           - Texto corto y visual para historia\n",
        "           - Incluye pregunta interactiva\n",
        "           - 30-40 palabras m√°ximo\n",
        "\n",
        "        5. **HASHTAGS ESTRAT√âGICOS**:\n",
        "           - 8-12 hashtags relevantes y trending\n",
        "           - Mix de hashtags populares y nicho\n",
        "           - Incluye hashtags locales (Colombia)\n",
        "\n",
        "        **ESTRATEGIA ADICIONAL:**\n",
        "        - Mejores horarios para publicar en cada plataforma\n",
        "        - Tipo de im√°genes/videos recomendados\n",
        "        - Estrategia de engagement y respuesta\n",
        "        - KPIs a monitorear\n",
        "        \"\"\",\n",
        "        agent=social_agent,\n",
        "        expected_output=\"Estrategia completa de redes sociales con contenido para m√∫ltiples plataformas\",\n",
        "        context=[editing_task]\n",
        "    )\n",
        "\n",
        "    return [research_task, writing_task, editing_task, social_task]\n",
        "\n",
        "# =============================================================================\n",
        "# FUNCI√ìN PRINCIPAL\n",
        "# =============================================================================\n",
        "\n",
        "def ejecutar_redaccion_digital(tema):\n",
        "    \"\"\"Ejecuta el flujo completo de la redacci√≥n digital\"\"\"\n",
        "\n",
        "    print(f\"üè¢ INICIANDO REDACCI√ìN DIGITAL CON OPENAI\")\n",
        "    print(f\"üì∞ Tema: {tema}\")\n",
        "    print(f\"ü§ñ Modelo: ChatGPT-4o-mini\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Inicializar tracker global\n",
        "    global global_tracker\n",
        "    global_tracker = NewsroomTracker()\n",
        "\n",
        "    # Configurar agentes\n",
        "    print(\"‚öôÔ∏è Configurando agentes...\")\n",
        "    agents = setup_newsroom_agents()\n",
        "\n",
        "    # Crear tareas\n",
        "    print(\"üìã Creando tareas...\")\n",
        "    tasks = create_newsroom_tasks(agents, tema)\n",
        "\n",
        "    # Configurar crew\n",
        "    print(\"üéØ Configurando crew...\")\n",
        "    newsroom_crew = Crew(\n",
        "        agents=list(agents),\n",
        "        tasks=tasks,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    # Ejecutar flujo de trabajo\n",
        "    print(\"üöÄ Ejecutando flujo de trabajo...\")\n",
        "    print(\"   1Ô∏è‚É£ Investigaci√≥n en curso...\")\n",
        "    print(\"   2Ô∏è‚É£ Redacci√≥n en espera...\")\n",
        "    print(\"   3Ô∏è‚É£ Edici√≥n en espera...\")\n",
        "    print(\"   4Ô∏è‚É£ Social media en espera...\")\n",
        "    print(\"-\"*60)\n",
        "\n",
        "    # Ejecutar y capturar resultados\n",
        "    crew_result = newsroom_crew.kickoff()\n",
        "\n",
        "    # Obtener resultados individuales de cada tarea\n",
        "    task_results = {}\n",
        "    if hasattr(crew_result, 'tasks_output') and crew_result.tasks_output:\n",
        "        for i, task_output in enumerate(crew_result.tasks_output):\n",
        "            task_names = ['investigacion', 'articulo', 'edicion', 'redes_sociales']\n",
        "            if i < len(task_names):\n",
        "                task_results[task_names[i]] = task_output.raw if hasattr(task_output, 'raw') else str(task_output)\n",
        "    else:\n",
        "        # Fallback: intentar acceder a las tareas directamente\n",
        "        for i, task in enumerate(tasks):\n",
        "            task_names = ['investigacion', 'articulo', 'edicion', 'redes_sociales']\n",
        "            if i < len(task_names) and hasattr(task, 'output'):\n",
        "                task_results[task_names[i]] = task.output.raw if hasattr(task.output, 'raw') else str(task.output)\n",
        "\n",
        "    # Si no se pudieron obtener resultados individuales, usar el resultado final\n",
        "    if not task_results:\n",
        "        task_results['redes_sociales'] = str(crew_result)\n",
        "\n",
        "    # Generar reporte final completo\n",
        "    final_report = f\"\"\"\n",
        "# üì∞ PRODUCCI√ìN EDITORIAL COMPLETA\n",
        "## Tema: {tema}\n",
        "## Modelo: ChatGPT-4o-mini (OpenAI)\n",
        "{'='*80}\n",
        "\n",
        "## üîç 1. INVESTIGACI√ìN REALIZADA\n",
        "{task_results.get('investigacion', 'No disponible')}\n",
        "\n",
        "{'='*60}\n",
        "\n",
        "## ‚úçÔ∏è 2. ART√çCULO REDACTADO\n",
        "{task_results.get('articulo', 'No disponible')}\n",
        "\n",
        "{'='*60}\n",
        "\n",
        "## üìù 3. ART√çCULO EDITADO\n",
        "{task_results.get('edicion', 'No disponible')}\n",
        "\n",
        "{'='*60}\n",
        "\n",
        "## üì± 4. CONTENIDO PARA REDES SOCIALES\n",
        "{task_results.get('redes_sociales', str(crew_result))}\n",
        "\n",
        "{'='*80}\n",
        "{global_tracker.get_sources_summary()}\n",
        "\n",
        "---\n",
        "‚úÖ **PROCESO COMPLETADO EXITOSAMENTE**\n",
        "ü§ñ 4 agentes especializados trabajaron en colaboraci√≥n\n",
        "üìä {len(global_tracker.sources)} fuentes consultadas y verificadas\n",
        "üîó **Pipeline ejecutado**: Investigaci√≥n ‚Üí Redacci√≥n ‚Üí Edici√≥n ‚Üí Social Media\n",
        "‚ö° **Modelo utilizado**: ChatGPT-4o-mini para m√°xima estabilidad\n",
        "üìã **Tareas completadas**: {len([k for k, v in task_results.items() if v != 'No disponible'])}/4\n",
        "\"\"\"\n",
        "\n",
        "    return final_report\n",
        "\n",
        "# =============================================================================\n",
        "# EJEMPLO DE USO\n",
        "# =============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Ejecutar con tema espec√≠fico\n",
        "    resultado = ejecutar_redaccion_digital(\"Nuevas regulaciones de IA en Colombia 2025\")\n",
        "    print(resultado)"
      ],
      "metadata": {
        "id": "rPzo4rYAh9OA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
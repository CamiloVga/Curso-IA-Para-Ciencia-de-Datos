{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPu7d4XupGA8YLjsn+QrxZ8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CamiloVga/Curso-IA-Para-Ciencia-de-Datos/blob/main/GenBI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "id": "PBRroyiJHwge",
        "outputId": "68c2d1d6-c489-4c50-f6d2-0de3c183ba4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Instalando componentes necesarios...\n",
            "üì¶ Instalando Ollama...\n",
            "üì• Descargando modelo llama3.1:8b...\n",
            "‚úÖ Instalaci√≥n completada\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2230760856.py:1315: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ú® GenBI Inteligente est√° listo!\n",
            "üåê Abriendo interfaz web...\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://8d4b69cc238804de9d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8d4b69cc238804de9d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 0. Instalaciones b√°sicas\n",
        "!pip install -q gradio pandas plotly sqlalchemy openpyxl xlrd seaborn matplotlib wordcloud\n",
        "\n",
        "# 1. Importaciones y configuraci√≥n\n",
        "import subprocess\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sqlite3\n",
        "import gradio as gr\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from io import StringIO\n",
        "import time\n",
        "import os\n",
        "import re\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Tuple, Optional, Any\n",
        "\n",
        "# Configuraci√≥n de modelos\n",
        "MODELO_SQL = \"llama3.1:8b\"\n",
        "MODELO_ANALISIS = \"llama3.1:8b\"\n",
        "TEMPERATURA_SQL = 0.1\n",
        "TEMPERATURA_ANALISIS = 0.3\n",
        "\n",
        "# 2. Instalador de Ollama mejorado\n",
        "def instalar_ollama():\n",
        "    \"\"\"Instala Ollama si no est√° disponible\"\"\"\n",
        "    try:\n",
        "        subprocess.run(['ollama', '--version'], capture_output=True, check=True)\n",
        "        print(\"‚úÖ Ollama ya instalado\")\n",
        "    except:\n",
        "        print(\"üì¶ Instalando Ollama...\")\n",
        "        os.system('curl -fsSL https://ollama.com/install.sh | sh')\n",
        "        os.system('pkill ollama || true')\n",
        "        os.system('nohup /usr/local/bin/ollama serve > /dev/null 2>&1 &')\n",
        "        time.sleep(10)\n",
        "\n",
        "        # Descargar modelos necesarios\n",
        "        print(f\"üì• Descargando modelo {MODELO_SQL}...\")\n",
        "        os.system(f'ollama pull {MODELO_SQL}')\n",
        "        if MODELO_ANALISIS != MODELO_SQL:\n",
        "            print(f\"üì• Descargando modelo {MODELO_ANALISIS}...\")\n",
        "            os.system(f'ollama pull {MODELO_ANALISIS}')\n",
        "        print(\"‚úÖ Instalaci√≥n completada\")\n",
        "\n",
        "# 3. Clase principal GenBI mejorada\n",
        "class GenBIMejorado:\n",
        "    def __init__(self):\n",
        "        self.db = sqlite3.connect(\":memory:\", check_same_thread=False)\n",
        "        self.tablas = {}\n",
        "        self.preguntas_sugeridas = []\n",
        "        self.datos_cargados = False\n",
        "        self.historial_consultas = []\n",
        "        self.cache_respuestas = {}\n",
        "\n",
        "        # Patrones de interpretaci√≥n de consultas\n",
        "        self.patrones_consultas = {\n",
        "            'agregacion': {\n",
        "                'total': ['total', 'suma', 'sumar', 'cu√°nto', 'cuanto'],\n",
        "                'promedio': ['promedio', 'media', 'average', 'avg'],\n",
        "                'maximo': ['m√°ximo', 'maximo', 'max', 'mayor', 'm√°s alto'],\n",
        "                'minimo': ['m√≠nimo', 'minimo', 'min', 'menor', 'm√°s bajo'],\n",
        "                'conteo': ['cu√°ntos', 'cuantos', 'contar', 'cantidad', 'n√∫mero']\n",
        "            },\n",
        "            'temporal': {\n",
        "                'tendencia': ['evoluci√≥n', 'evolucion', 'tendencia', 'hist√≥rico', 'historico', 'tiempo'],\n",
        "                'periodo': ['mes', 'a√±o', 'semana', 'd√≠a', 'trimestre', 'fecha']\n",
        "            },\n",
        "            'comparacion': {\n",
        "                'versus': ['vs', 'versus', 'comparar', 'comparaci√≥n', 'diferencia'],\n",
        "                'ranking': ['top', 'mejores', 'peores', 'ranking', 'primeros', '√∫ltimos']\n",
        "            },\n",
        "            'distribucion': {\n",
        "                'porcentaje': ['porcentaje', '%', 'proporci√≥n', 'proporcion', 'distribuci√≥n'],\n",
        "                'agrupacion': ['por', 'seg√∫n', 'segun', 'agrupar', 'categor√≠a']\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def leer_archivo(self, archivo_path: str) -> Tuple[Optional[pd.DataFrame], str]:\n",
        "        \"\"\"Lee m√∫ltiples formatos de archivo con mejor manejo de errores\"\"\"\n",
        "        try:\n",
        "            extension = os.path.splitext(archivo_path)[1].lower()\n",
        "\n",
        "            # Configuraciones espec√≠ficas por formato\n",
        "            if extension == '.csv':\n",
        "                # Intentar diferentes encodings y separadores\n",
        "                for encoding in ['utf-8', 'latin-1', 'iso-8859-1']:\n",
        "                    for sep in [',', ';', '\\t', '|']:\n",
        "                        try:\n",
        "                            df = pd.read_csv(archivo_path, encoding=encoding, sep=sep)\n",
        "                            if len(df.columns) > 1:  # Verificar que se separ√≥ correctamente\n",
        "                                break\n",
        "                        except:\n",
        "                            continue\n",
        "                    else:\n",
        "                        continue\n",
        "                    break\n",
        "\n",
        "            elif extension in ['.xlsx', '.xls']:\n",
        "                # Leer Excel con soporte para m√∫ltiples hojas\n",
        "                excel_file = pd.ExcelFile(archivo_path)\n",
        "                if len(excel_file.sheet_names) > 1:\n",
        "                    # Si hay m√∫ltiples hojas, usar la primera o preguntar\n",
        "                    df = pd.read_excel(archivo_path, sheet_name=0)\n",
        "                else:\n",
        "                    df = pd.read_excel(archivo_path)\n",
        "\n",
        "            elif extension == '.json':\n",
        "                # Intentar diferentes orientaciones de JSON\n",
        "                try:\n",
        "                    df = pd.read_json(archivo_path)\n",
        "                except:\n",
        "                    df = pd.read_json(archivo_path, orient='records')\n",
        "\n",
        "            else:\n",
        "                return None, f\"‚ùå Formato no soportado: {extension}\"\n",
        "\n",
        "            # Limpiar nombres de columnas\n",
        "            df.columns = df.columns.str.strip().str.replace(' ', '_')\n",
        "\n",
        "            # Verificar que el DataFrame no est√© vac√≠o\n",
        "            if df.empty:\n",
        "                return None, \"‚ùå El archivo est√° vac√≠o\"\n",
        "\n",
        "            return df, \"‚úÖ Archivo le√≠do correctamente\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return None, f\"‚ùå Error leyendo archivo: {str(e)}\"\n",
        "\n",
        "    def detectar_tipos_inteligente(self, df: pd.DataFrame) -> Dict[str, List[str]]:\n",
        "        \"\"\"Detecci√≥n inteligente de tipos de datos con inferencia mejorada\"\"\"\n",
        "        tipos = {\n",
        "            'numericas': [],\n",
        "            'categoricas': [],\n",
        "            'fechas': [],\n",
        "            'booleanas': [],\n",
        "            'ids': [],\n",
        "            'textos_largos': []\n",
        "        }\n",
        "\n",
        "        for col in df.columns:\n",
        "            col_data = df[col].dropna()\n",
        "\n",
        "            if len(col_data) == 0:\n",
        "                continue\n",
        "\n",
        "            # Detectar IDs (columnas con valores √∫nicos o casi √∫nicos)\n",
        "            if len(col_data.unique()) / len(col_data) > 0.95:\n",
        "                if col_data.dtype in ['int64', 'object']:\n",
        "                    tipos['ids'].append(col)\n",
        "                    continue\n",
        "\n",
        "            # Detectar fechas\n",
        "            if self._es_fecha(col_data):\n",
        "                try:\n",
        "                    df[col] = pd.to_datetime(df[col])\n",
        "                    tipos['fechas'].append(col)\n",
        "                    continue\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "            # Detectar booleanas\n",
        "            if col_data.dtype == 'bool' or set(col_data.unique()) <= {True, False, 0, 1, 'SI', 'NO', 'Yes', 'No'}:\n",
        "                tipos['booleanas'].append(col)\n",
        "                continue\n",
        "\n",
        "            # Detectar num√©ricas\n",
        "            if pd.api.types.is_numeric_dtype(col_data):\n",
        "                tipos['numericas'].append(col)\n",
        "            # Detectar textos largos vs categ√≥ricas\n",
        "            elif col_data.dtype == 'object':\n",
        "                avg_length = col_data.astype(str).str.len().mean()\n",
        "                unique_ratio = len(col_data.unique()) / len(col_data)\n",
        "\n",
        "                if avg_length > 50 or unique_ratio > 0.8:\n",
        "                    tipos['textos_largos'].append(col)\n",
        "                else:\n",
        "                    tipos['categoricas'].append(col)\n",
        "\n",
        "        return tipos\n",
        "\n",
        "    def _es_fecha(self, serie: pd.Series) -> bool:\n",
        "        \"\"\"Detecta si una serie contiene fechas\"\"\"\n",
        "        if serie.dtype == 'datetime64[ns]':\n",
        "            return True\n",
        "\n",
        "        # Patrones comunes de fecha\n",
        "        patrones_fecha = [\n",
        "            r'\\d{4}-\\d{2}-\\d{2}',  # YYYY-MM-DD\n",
        "            r'\\d{2}/\\d{2}/\\d{4}',  # DD/MM/YYYY o MM/DD/YYYY\n",
        "            r'\\d{2}-\\d{2}-\\d{4}',  # DD-MM-YYYY\n",
        "        ]\n",
        "\n",
        "        if serie.dtype == 'object':\n",
        "            muestra = serie.head(10).astype(str)\n",
        "            for patron in patrones_fecha:\n",
        "                if muestra.str.match(patron).any():\n",
        "                    return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def generar_preguntas_inteligentes(self, info_tabla: Dict, nombre_tabla: str) -> List[str]:\n",
        "        \"\"\"Genera preguntas m√°s inteligentes y contextualizadas\"\"\"\n",
        "        preguntas = []\n",
        "\n",
        "        # Preguntas b√°sicas siempre √∫tiles\n",
        "        preguntas.append(f\"¬øCu√°ntos registros hay en total?\")\n",
        "        preguntas.append(f\"Mu√©strame un resumen general de los datos\")\n",
        "\n",
        "        # Preguntas para num√©ricas\n",
        "        if info_tabla['numericas']:\n",
        "            col_principal = info_tabla['numericas'][0]\n",
        "            preguntas.append(f\"¬øCu√°l es el total y promedio de {col_principal}?\")\n",
        "\n",
        "            if len(info_tabla['numericas']) >= 2:\n",
        "                col2 = info_tabla['numericas'][1]\n",
        "                preguntas.append(f\"¬øExiste correlaci√≥n entre {col_principal} y {col2}?\")\n",
        "\n",
        "        # Preguntas para categ√≥ricas\n",
        "        if info_tabla['categoricas']:\n",
        "            cat_principal = info_tabla['categoricas'][0]\n",
        "            if info_tabla['numericas']:\n",
        "                num_principal = info_tabla['numericas'][0]\n",
        "                preguntas.append(f\"¬øC√≥mo se distribuye {num_principal} por {cat_principal}?\")\n",
        "                preguntas.append(f\"¬øCu√°les son los top 5 {cat_principal} con mayor {num_principal}?\")\n",
        "            else:\n",
        "                preguntas.append(f\"¬øCu√°l es la distribuci√≥n de {cat_principal}?\")\n",
        "\n",
        "        # Preguntas temporales\n",
        "        if info_tabla['fechas']:\n",
        "            fecha_col = info_tabla['fechas'][0]\n",
        "            if info_tabla['numericas']:\n",
        "                preguntas.append(f\"¬øC√≥mo ha evolucionado {info_tabla['numericas'][0]} en el tiempo?\")\n",
        "            preguntas.append(f\"¬øCu√°l es el rango de fechas en los datos?\")\n",
        "\n",
        "        # Preguntas de an√°lisis avanzado\n",
        "        if len(info_tabla['numericas']) >= 2:\n",
        "            preguntas.append(\"¬øCu√°les son las principales correlaciones entre variables num√©ricas?\")\n",
        "\n",
        "        if info_tabla['categoricas'] and info_tabla['numericas']:\n",
        "            preguntas.append(\"¬øQu√© categor√≠as tienen valores at√≠picos o extremos?\")\n",
        "\n",
        "        return preguntas[:8]  # Retornar hasta 8 preguntas\n",
        "\n",
        "    def interpretar_consulta(self, pregunta: str) -> Dict[str, Any]:\n",
        "        \"\"\"Interpreta la consulta del usuario para entender mejor qu√© busca\"\"\"\n",
        "        pregunta_lower = pregunta.lower()\n",
        "        interpretacion = {\n",
        "            'tipo_consulta': 'general',\n",
        "            'agregaciones': [],\n",
        "            'columnas_mencionadas': [],\n",
        "            'filtros': [],\n",
        "            'agrupaciones': [],\n",
        "            'ordenamiento': None,\n",
        "            'limite': None,\n",
        "            'tipo_visualizacion': 'tabla'\n",
        "        }\n",
        "\n",
        "        # Detectar tipo de consulta principal\n",
        "        for tipo, palabras in self.patrones_consultas['agregacion'].items():\n",
        "            if any(palabra in pregunta_lower for palabra in palabras):\n",
        "                interpretacion['agregaciones'].append(tipo)\n",
        "                interpretacion['tipo_consulta'] = 'agregacion'\n",
        "\n",
        "        # Detectar consultas temporales\n",
        "        if any(palabra in pregunta_lower for palabra in self.patrones_consultas['temporal']['tendencia']):\n",
        "            interpretacion['tipo_consulta'] = 'temporal'\n",
        "            interpretacion['tipo_visualizacion'] = 'linea'\n",
        "\n",
        "        # Detectar comparaciones\n",
        "        if any(palabra in pregunta_lower for palabra in self.patrones_consultas['comparacion']['versus']):\n",
        "            interpretacion['tipo_consulta'] = 'comparacion'\n",
        "            interpretacion['tipo_visualizacion'] = 'barra_agrupada'\n",
        "\n",
        "        # Detectar rankings\n",
        "        if any(palabra in pregunta_lower for palabra in self.patrones_consultas['comparacion']['ranking']):\n",
        "            interpretacion['tipo_consulta'] = 'ranking'\n",
        "            # Extraer n√∫mero del top\n",
        "            match = re.search(r'top\\s*(\\d+)', pregunta_lower)\n",
        "            if match:\n",
        "                interpretacion['limite'] = int(match.group(1))\n",
        "            else:\n",
        "                interpretacion['limite'] = 10\n",
        "\n",
        "        # Detectar distribuciones\n",
        "        if any(palabra in pregunta_lower for palabra in self.patrones_consultas['distribucion']['porcentaje']):\n",
        "            interpretacion['tipo_consulta'] = 'distribucion'\n",
        "            interpretacion['tipo_visualizacion'] = 'pie'\n",
        "\n",
        "        # Detectar columnas mencionadas\n",
        "        for tabla, info in self.tablas.items():\n",
        "            for col in info['columnas']:\n",
        "                if col.lower() in pregunta_lower or col.lower().replace('_', ' ') in pregunta_lower:\n",
        "                    interpretacion['columnas_mencionadas'].append(col)\n",
        "\n",
        "        return interpretacion\n",
        "\n",
        "    def generar_sql_inteligente(self, pregunta: str, interpretacion: Dict[str, Any]) -> str:\n",
        "        \"\"\"Genera SQL m√°s inteligente basado en la interpretaci√≥n de la consulta\"\"\"\n",
        "        if not self.tablas:\n",
        "            return \"SELECT 'No hay datos cargados' as mensaje;\"\n",
        "\n",
        "        tabla_principal = list(self.tablas.keys())[0]\n",
        "        info_tabla = self.tablas[tabla_principal]\n",
        "\n",
        "        # SQL seg√∫n tipo de consulta\n",
        "        if interpretacion['tipo_consulta'] == 'general':\n",
        "            # Consulta general - mostrar resumen\n",
        "            return f\"SELECT * FROM {tabla_principal} LIMIT 10;\"\n",
        "\n",
        "        elif interpretacion['tipo_consulta'] == 'agregacion':\n",
        "            return self._generar_sql_agregacion(tabla_principal, info_tabla, interpretacion)\n",
        "\n",
        "        elif interpretacion['tipo_consulta'] == 'temporal':\n",
        "            return self._generar_sql_temporal(tabla_principal, info_tabla, interpretacion)\n",
        "\n",
        "        elif interpretacion['tipo_consulta'] == 'ranking':\n",
        "            return self._generar_sql_ranking(tabla_principal, info_tabla, interpretacion)\n",
        "\n",
        "        elif interpretacion['tipo_consulta'] == 'distribucion':\n",
        "            return self._generar_sql_distribucion(tabla_principal, info_tabla, interpretacion)\n",
        "\n",
        "        elif interpretacion['tipo_consulta'] == 'comparacion':\n",
        "            return self._generar_sql_comparacion(tabla_principal, info_tabla, interpretacion)\n",
        "\n",
        "        else:\n",
        "            # Fallback a generaci√≥n con Ollama\n",
        "            return self.generar_sql_con_llm(pregunta)\n",
        "\n",
        "    def _generar_sql_agregacion(self, tabla: str, info: Dict, interp: Dict) -> str:\n",
        "        \"\"\"Genera SQL para consultas de agregaci√≥n\"\"\"\n",
        "        cols_num = info['numericas']\n",
        "        cols_cat = info['categoricas']\n",
        "\n",
        "        if not cols_num:\n",
        "            return f\"SELECT COUNT(*) as total_registros FROM {tabla};\"\n",
        "\n",
        "        # Determinar columna num√©rica a usar\n",
        "        col_num = cols_num[0]\n",
        "        if interp['columnas_mencionadas']:\n",
        "            for col in interp['columnas_mencionadas']:\n",
        "                if col in cols_num:\n",
        "                    col_num = col\n",
        "                    break\n",
        "\n",
        "        # Construir agregaciones\n",
        "        agregaciones = []\n",
        "        if 'total' in interp['agregaciones']:\n",
        "            agregaciones.append(f\"SUM({col_num}) as total_{col_num}\")\n",
        "        if 'promedio' in interp['agregaciones']:\n",
        "            agregaciones.append(f\"AVG({col_num}) as promedio_{col_num}\")\n",
        "        if 'maximo' in interp['agregaciones']:\n",
        "            agregaciones.append(f\"MAX({col_num}) as maximo_{col_num}\")\n",
        "        if 'minimo' in interp['agregaciones']:\n",
        "            agregaciones.append(f\"MIN({col_num}) as minimo_{col_num}\")\n",
        "        if 'conteo' in interp['agregaciones']:\n",
        "            agregaciones.append(f\"COUNT(*) as cantidad\")\n",
        "\n",
        "        if not agregaciones:\n",
        "            agregaciones = [f\"SUM({col_num}) as total\", f\"AVG({col_num}) as promedio\", \"COUNT(*) as cantidad\"]\n",
        "\n",
        "        # Determinar si hay agrupaci√≥n\n",
        "        group_by = \"\"\n",
        "        if cols_cat and any(cat in interp['columnas_mencionadas'] for cat in cols_cat):\n",
        "            col_cat = next((cat for cat in cols_cat if cat in interp['columnas_mencionadas']), cols_cat[0])\n",
        "            group_by = f\" GROUP BY {col_cat}\"\n",
        "\n",
        "        sql = f\"SELECT {', '.join(agregaciones)} FROM {tabla}{group_by};\"\n",
        "        return sql\n",
        "\n",
        "    def _generar_sql_temporal(self, tabla: str, info: Dict, interp: Dict) -> str:\n",
        "        \"\"\"Genera SQL para an√°lisis temporal\"\"\"\n",
        "        if not info['fechas'] or not info['numericas']:\n",
        "            return f\"SELECT * FROM {tabla} LIMIT 20;\"\n",
        "\n",
        "        fecha_col = info['fechas'][0]\n",
        "        num_col = info['numericas'][0]\n",
        "\n",
        "        # Buscar columna num√©rica mencionada\n",
        "        for col in interp['columnas_mencionadas']:\n",
        "            if col in info['numericas']:\n",
        "                num_col = col\n",
        "                break\n",
        "\n",
        "        sql = f\"\"\"\n",
        "        SELECT\n",
        "            DATE({fecha_col}) as fecha,\n",
        "            SUM({num_col}) as total_{num_col},\n",
        "            AVG({num_col}) as promedio_{num_col},\n",
        "            COUNT(*) as registros\n",
        "        FROM {tabla}\n",
        "        WHERE {fecha_col} IS NOT NULL\n",
        "        GROUP BY DATE({fecha_col})\n",
        "        ORDER BY fecha;\n",
        "        \"\"\"\n",
        "\n",
        "        return sql.strip()\n",
        "\n",
        "    def _generar_sql_ranking(self, tabla: str, info: Dict, interp: Dict) -> str:\n",
        "        \"\"\"Genera SQL para rankings\"\"\"\n",
        "        limite = interp['limite'] or 10\n",
        "\n",
        "        if not info['numericas']:\n",
        "            # Ranking por conteo\n",
        "            if info['categoricas']:\n",
        "                col_cat = info['categoricas'][0]\n",
        "                return f\"\"\"\n",
        "                SELECT {col_cat}, COUNT(*) as cantidad\n",
        "                FROM {tabla}\n",
        "                GROUP BY {col_cat}\n",
        "                ORDER BY cantidad DESC\n",
        "                LIMIT {limite};\n",
        "                \"\"\"\n",
        "        else:\n",
        "            num_col = info['numericas'][0]\n",
        "            if info['categoricas']:\n",
        "                cat_col = info['categoricas'][0]\n",
        "                return f\"\"\"\n",
        "                SELECT {cat_col}, SUM({num_col}) as total_{num_col}\n",
        "                FROM {tabla}\n",
        "                GROUP BY {cat_col}\n",
        "                ORDER BY total_{num_col} DESC\n",
        "                LIMIT {limite};\n",
        "                \"\"\"\n",
        "            else:\n",
        "                return f\"\"\"\n",
        "                SELECT *\n",
        "                FROM {tabla}\n",
        "                ORDER BY {num_col} DESC\n",
        "                LIMIT {limite};\n",
        "                \"\"\"\n",
        "\n",
        "    def _generar_sql_distribucion(self, tabla: str, info: Dict, interp: Dict) -> str:\n",
        "        \"\"\"Genera SQL para distribuciones y porcentajes\"\"\"\n",
        "        if not info['categoricas']:\n",
        "            return f\"SELECT COUNT(*) as total FROM {tabla};\"\n",
        "\n",
        "        col_cat = info['categoricas'][0]\n",
        "        # Buscar columna categ√≥rica mencionada\n",
        "        for col in interp['columnas_mencionadas']:\n",
        "            if col in info['categoricas']:\n",
        "                col_cat = col\n",
        "                break\n",
        "\n",
        "        sql = f\"\"\"\n",
        "        SELECT\n",
        "            {col_cat},\n",
        "            COUNT(*) as cantidad,\n",
        "            ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM {tabla}), 2) as porcentaje\n",
        "        FROM {tabla}\n",
        "        GROUP BY {col_cat}\n",
        "        ORDER BY cantidad DESC;\n",
        "        \"\"\"\n",
        "\n",
        "        return sql.strip()\n",
        "\n",
        "    def _generar_sql_comparacion(self, tabla: str, info: Dict, interp: Dict) -> str:\n",
        "        \"\"\"Genera SQL para comparaciones\"\"\"\n",
        "        if len(info['numericas']) >= 2:\n",
        "            # Comparar dos variables num√©ricas\n",
        "            return f\"\"\"\n",
        "            SELECT {info['numericas'][0]}, {info['numericas'][1]}\n",
        "            FROM {tabla}\n",
        "            WHERE {info['numericas'][0]} IS NOT NULL\n",
        "            AND {info['numericas'][1]} IS NOT NULL;\n",
        "            \"\"\"\n",
        "        elif info['categoricas'] and info['numericas']:\n",
        "            # Comparar categor√≠as\n",
        "            return f\"\"\"\n",
        "            SELECT\n",
        "                {info['categoricas'][0]},\n",
        "                AVG({info['numericas'][0]}) as promedio,\n",
        "                MIN({info['numericas'][0]}) as minimo,\n",
        "                MAX({info['numericas'][0]}) as maximo\n",
        "            FROM {tabla}\n",
        "            GROUP BY {info['categoricas'][0]};\n",
        "            \"\"\"\n",
        "        else:\n",
        "            return f\"SELECT * FROM {tabla} LIMIT 20;\"\n",
        "\n",
        "    def generar_sql_con_llm(self, pregunta: str) -> str:\n",
        "        \"\"\"Genera SQL usando el modelo de lenguaje cuando las reglas no son suficientes\"\"\"\n",
        "        contexto = self.obtener_contexto_detallado()\n",
        "\n",
        "        prompt = f\"\"\"Eres un experto en SQL para SQLite. Genera SQL preciso basado en la pregunta del usuario.\n",
        "\n",
        "ESQUEMA DE LA BASE DE DATOS:\n",
        "{contexto}\n",
        "\n",
        "PREGUNTA DEL USUARIO: {pregunta}\n",
        "\n",
        "REGLAS IMPORTANTES:\n",
        "1. Usa SOLO los nombres exactos de tablas y columnas del esquema\n",
        "2. Genera SQL v√°lido para SQLite\n",
        "3. Si la pregunta pide distribuci√≥n o porcentajes, usa COUNT(*) y GROUP BY\n",
        "4. Para porcentajes usa: COUNT(*) * 100.0 / (SELECT COUNT(*) FROM tabla)\n",
        "5. NO incluyas comentarios en el SQL\n",
        "6. Termina con punto y coma\n",
        "\n",
        "Responde √öNICAMENTE con el SQL:\"\"\"\n",
        "\n",
        "        respuesta = self.consultar_ollama(prompt, MODELO_SQL, TEMPERATURA_SQL)\n",
        "\n",
        "        # Extraer solo el SQL de la respuesta\n",
        "        sql = self._extraer_sql_de_respuesta(respuesta)\n",
        "        return sql\n",
        "\n",
        "    def _extraer_sql_de_respuesta(self, respuesta: str) -> str:\n",
        "        \"\"\"Extrae SQL limpio de la respuesta del modelo\"\"\"\n",
        "        # Buscar el primer SELECT, WITH, o INSERT\n",
        "        lineas = respuesta.strip().split('\\n')\n",
        "        sql_keywords = ['SELECT', 'WITH', 'INSERT', 'UPDATE', 'DELETE']\n",
        "\n",
        "        sql_encontrado = []\n",
        "        en_sql = False\n",
        "\n",
        "        for linea in lineas:\n",
        "            linea_upper = linea.strip().upper()\n",
        "\n",
        "            # Iniciar captura si encontramos palabra clave SQL\n",
        "            if any(linea_upper.startswith(kw) for kw in sql_keywords):\n",
        "                en_sql = True\n",
        "\n",
        "            if en_sql:\n",
        "                # Dejar de capturar si encontramos algo que no es SQL\n",
        "                if linea.strip() and not any(char in linea for char in [';', ',', '(', ')', 'SELECT', 'FROM', 'WHERE', 'GROUP', 'ORDER']):\n",
        "                    if not linea.strip().endswith(';'):\n",
        "                        break\n",
        "\n",
        "                sql_encontrado.append(linea)\n",
        "\n",
        "                # Si termina con punto y coma, terminar\n",
        "                if linea.strip().endswith(';'):\n",
        "                    break\n",
        "\n",
        "        sql = '\\n'.join(sql_encontrado).strip()\n",
        "\n",
        "        # Si no se encontr√≥ SQL v√°lido, intentar extraer de otra forma\n",
        "        if not sql:\n",
        "            # Buscar entre comillas o c√≥digo\n",
        "            match = re.search(r'```sql?\\s*(.*?)```', respuesta, re.DOTALL)\n",
        "            if match:\n",
        "                sql = match.group(1).strip()\n",
        "            else:\n",
        "                # √öltimo intento: tomar la primera l√≠nea que parezca SQL\n",
        "                for linea in lineas:\n",
        "                    if any(kw in linea.upper() for kw in sql_keywords):\n",
        "                        sql = linea.strip()\n",
        "                        break\n",
        "\n",
        "        # Asegurar que termine con punto y coma\n",
        "        if sql and not sql.endswith(';'):\n",
        "            sql += ';'\n",
        "\n",
        "        return sql or \"SELECT 'No se pudo generar SQL' as error;\"\n",
        "\n",
        "    def consultar_ollama(self, prompt: str, modelo: str, temperatura: float) -> str:\n",
        "        \"\"\"Consulta el modelo Ollama con mejor manejo de errores\"\"\"\n",
        "        # Escapar caracteres especiales en el prompt\n",
        "        prompt_escapado = json.dumps(prompt)\n",
        "\n",
        "        comando = f'curl -s http://localhost:11434/api/generate -d \\'{{\"model\": \"{modelo}\", \"prompt\": {prompt_escapado}, \"stream\": false, \"temperature\": {temperatura}}}\\''\n",
        "\n",
        "        try:\n",
        "            resultado = subprocess.run(comando, shell=True, capture_output=True, text=True, timeout=30)\n",
        "\n",
        "            if resultado.returncode == 0 and resultado.stdout:\n",
        "                data = json.loads(resultado.stdout)\n",
        "                return data.get('response', 'Sin respuesta del modelo')\n",
        "            else:\n",
        "                return f\"Error en la consulta: {resultado.stderr}\"\n",
        "\n",
        "        except subprocess.TimeoutExpired:\n",
        "            return \"Timeout: La consulta tard√≥ demasiado tiempo\"\n",
        "        except json.JSONDecodeError:\n",
        "            return \"Error decodificando la respuesta del modelo\"\n",
        "        except Exception as e:\n",
        "            return f\"Error inesperado: {str(e)}\"\n",
        "\n",
        "    def ejecutar_sql(self, sql: str) -> Tuple[pd.DataFrame, str]:\n",
        "        \"\"\"Ejecuta SQL con mejor manejo de errores y validaci√≥n\"\"\"\n",
        "        try:\n",
        "            # Validaci√≥n b√°sica del SQL\n",
        "            sql_upper = sql.upper()\n",
        "            if any(palabra in sql_upper for palabra in ['DROP', 'DELETE', 'TRUNCATE', 'ALTER']):\n",
        "                return pd.DataFrame(), \"‚ùå Operaci√≥n no permitida por seguridad\"\n",
        "\n",
        "            # Ejecutar consulta\n",
        "            df = pd.read_sql_query(sql, self.db)\n",
        "\n",
        "            # Verificar resultados\n",
        "            if df.empty:\n",
        "                return df, \"‚ö†Ô∏è La consulta no devolvi√≥ resultados\"\n",
        "            else:\n",
        "                return df, f\"‚úÖ {len(df)} filas obtenidas\"\n",
        "\n",
        "        except sqlite3.OperationalError as e:\n",
        "            return pd.DataFrame(), f\"‚ùå Error SQL: {str(e)}\"\n",
        "        except Exception as e:\n",
        "            return pd.DataFrame(), f\"‚ùå Error inesperado: {str(e)}\"\n",
        "\n",
        "    def crear_visualizacion_inteligente(self, datos: pd.DataFrame, interpretacion: Dict[str, Any]) -> Optional[go.Figure]:\n",
        "        \"\"\"Crea visualizaciones m√°s inteligentes seg√∫n el tipo de datos y consulta\"\"\"\n",
        "        if datos.empty:\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            # Determinar tipo de visualizaci√≥n seg√∫n la interpretaci√≥n\n",
        "            tipo_viz = interpretacion.get('tipo_visualizacion', 'auto')\n",
        "\n",
        "            if tipo_viz == 'auto':\n",
        "                # Determinar autom√°ticamente el mejor tipo\n",
        "                tipo_viz = self._determinar_tipo_visualizacion(datos)\n",
        "\n",
        "            # Crear visualizaci√≥n seg√∫n el tipo\n",
        "            if tipo_viz == 'barra':\n",
        "                return self._crear_grafico_barras(datos)\n",
        "            elif tipo_viz == 'linea':\n",
        "                return self._crear_grafico_lineas(datos)\n",
        "            elif tipo_viz == 'pie':\n",
        "                return self._crear_grafico_pie(datos)\n",
        "            elif tipo_viz == 'scatter':\n",
        "                return self._crear_grafico_dispersion(datos)\n",
        "            elif tipo_viz == 'heatmap':\n",
        "                return self._crear_heatmap(datos)\n",
        "            elif tipo_viz == 'barra_agrupada':\n",
        "                return self._crear_barras_agrupadas(datos)\n",
        "            else:\n",
        "                # Visualizaci√≥n por defecto\n",
        "                return self._crear_visualizacion_automatica(datos)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error creando visualizaci√≥n: {e}\")\n",
        "            return None\n",
        "\n",
        "    def _determinar_tipo_visualizacion(self, datos: pd.DataFrame) -> str:\n",
        "        \"\"\"Determina el mejor tipo de visualizaci√≥n para los datos\"\"\"\n",
        "        num_cols = datos.select_dtypes(include=['number']).columns\n",
        "        cat_cols = datos.select_dtypes(include=['object']).columns\n",
        "        date_cols = datos.select_dtypes(include=['datetime']).columns\n",
        "\n",
        "        # Reglas para determinar visualizaci√≥n\n",
        "        if len(datos) == 1:\n",
        "            return 'indicador'  # Una sola fila, mostrar como indicador\n",
        "        elif len(date_cols) > 0 and len(num_cols) > 0:\n",
        "            return 'linea'  # Serie temporal\n",
        "        elif len(cat_cols) == 1 and len(num_cols) == 1 and len(datos) <= 20:\n",
        "            return 'barra'  # Categor√≠as con valores\n",
        "        elif len(cat_cols) == 1 and 'porcentaje' in datos.columns:\n",
        "            return 'pie'  # Distribuci√≥n porcentual\n",
        "        elif len(num_cols) >= 2 and len(datos) > 10:\n",
        "            return 'scatter'  # Relaci√≥n entre variables\n",
        "        elif len(num_cols) > 3:\n",
        "            return 'heatmap'  # M√∫ltiples correlaciones\n",
        "        else:\n",
        "            return 'barra'  # Por defecto\n",
        "\n",
        "    def _crear_grafico_barras(self, datos: pd.DataFrame) -> go.Figure:\n",
        "        \"\"\"Crea un gr√°fico de barras mejorado\"\"\"\n",
        "        # Identificar columnas\n",
        "        num_cols = datos.select_dtypes(include=['number']).columns\n",
        "        cat_cols = datos.select_dtypes(include=['object']).columns\n",
        "\n",
        "        if len(cat_cols) > 0 and len(num_cols) > 0:\n",
        "            x_col = cat_cols[0]\n",
        "            y_col = num_cols[0]\n",
        "\n",
        "            # Ordenar por valor si hay muchas categor√≠as\n",
        "            if len(datos) > 15:\n",
        "                datos = datos.nlargest(15, y_col)\n",
        "\n",
        "            fig = go.Figure(data=[\n",
        "                go.Bar(\n",
        "                    x=datos[x_col],\n",
        "                    y=datos[y_col],\n",
        "                    text=datos[y_col].round(2),\n",
        "                    textposition='auto',\n",
        "                    marker_color='rgba(55, 128, 191, 0.7)',\n",
        "                    marker_line_color='rgba(55, 128, 191, 1.0)',\n",
        "                    marker_line_width=1.5\n",
        "                )\n",
        "            ])\n",
        "\n",
        "            fig.update_layout(\n",
        "                title=f'{y_col} por {x_col}',\n",
        "                xaxis_title=x_col,\n",
        "                yaxis_title=y_col,\n",
        "                template='plotly_white',\n",
        "                showlegend=False,\n",
        "                height=500\n",
        "            )\n",
        "\n",
        "            # Rotar etiquetas si son largas\n",
        "            if datos[x_col].astype(str).str.len().mean() > 10:\n",
        "                fig.update_xaxes(tickangle=-45)\n",
        "\n",
        "            return fig\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _crear_grafico_lineas(self, datos: pd.DataFrame) -> go.Figure:\n",
        "        \"\"\"Crea un gr√°fico de l√≠neas para series temporales\"\"\"\n",
        "        date_cols = datos.select_dtypes(include=['datetime']).columns\n",
        "        num_cols = datos.select_dtypes(include=['number']).columns\n",
        "\n",
        "        if len(date_cols) > 0 and len(num_cols) > 0:\n",
        "            x_col = date_cols[0]\n",
        "\n",
        "            fig = go.Figure()\n",
        "\n",
        "            # Agregar una l√≠nea por cada columna num√©rica\n",
        "            colors = px.colors.qualitative.Set3\n",
        "            for i, y_col in enumerate(num_cols[:5]):  # M√°ximo 5 l√≠neas\n",
        "                fig.add_trace(go.Scatter(\n",
        "                    x=datos[x_col],\n",
        "                    y=datos[y_col],\n",
        "                    mode='lines+markers',\n",
        "                    name=y_col,\n",
        "                    line=dict(color=colors[i % len(colors)], width=2),\n",
        "                    marker=dict(size=6)\n",
        "                ))\n",
        "\n",
        "            fig.update_layout(\n",
        "                title='Evoluci√≥n temporal',\n",
        "                xaxis_title='Fecha',\n",
        "                yaxis_title='Valores',\n",
        "                template='plotly_white',\n",
        "                height=500,\n",
        "                hovermode='x unified'\n",
        "            )\n",
        "\n",
        "            return fig\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _crear_grafico_pie(self, datos: pd.DataFrame) -> go.Figure:\n",
        "        \"\"\"Crea un gr√°fico circular para distribuciones\"\"\"\n",
        "        # Buscar columnas de categor√≠a y valor\n",
        "        cat_cols = datos.select_dtypes(include=['object']).columns\n",
        "        num_cols = datos.select_dtypes(include=['number']).columns\n",
        "\n",
        "        if len(cat_cols) > 0 and len(num_cols) > 0:\n",
        "            labels_col = cat_cols[0]\n",
        "            values_col = num_cols[0]\n",
        "\n",
        "            # Limitar a top 10 categor√≠as si hay muchas\n",
        "            if len(datos) > 10:\n",
        "                otros = datos.nsmallest(len(datos) - 10, values_col)[values_col].sum()\n",
        "                datos = datos.nlargest(10, values_col)\n",
        "                if otros > 0:\n",
        "                    datos = pd.concat([\n",
        "                        datos,\n",
        "                        pd.DataFrame({labels_col: ['Otros'], values_col: [otros]})\n",
        "                    ])\n",
        "\n",
        "            fig = go.Figure(data=[go.Pie(\n",
        "                labels=datos[labels_col],\n",
        "                values=datos[values_col],\n",
        "                hole=0.3,\n",
        "                textinfo='label+percent',\n",
        "                textposition='auto'\n",
        "            )])\n",
        "\n",
        "            fig.update_layout(\n",
        "                title=f'Distribuci√≥n de {values_col} por {labels_col}',\n",
        "                template='plotly_white',\n",
        "                height=500\n",
        "            )\n",
        "\n",
        "            return fig\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _crear_grafico_dispersion(self, datos: pd.DataFrame) -> go.Figure:\n",
        "        \"\"\"Crea un gr√°fico de dispersi√≥n para relaciones entre variables\"\"\"\n",
        "        num_cols = list(datos.select_dtypes(include=['number']).columns)\n",
        "        cat_cols = list(datos.select_dtypes(include=['object']).columns)\n",
        "\n",
        "        if len(num_cols) >= 2:\n",
        "            x_col = num_cols[0]\n",
        "            y_col = num_cols[1]\n",
        "\n",
        "            # Color por categor√≠a si existe\n",
        "            color_col = cat_cols[0] if cat_cols else None\n",
        "            size_col = num_cols[2] if len(num_cols) > 2 else None\n",
        "\n",
        "            fig = px.scatter(\n",
        "                datos,\n",
        "                x=x_col,\n",
        "                y=y_col,\n",
        "                color=color_col,\n",
        "                size=size_col,\n",
        "                title=f'Relaci√≥n entre {x_col} y {y_col}',\n",
        "                template='plotly_white',\n",
        "                height=500\n",
        "            )\n",
        "\n",
        "            # Agregar l√≠nea de tendencia si no hay categor√≠as\n",
        "            if not color_col and len(datos) > 10:\n",
        "                fig.add_trace(go.Scatter(\n",
        "                    x=datos[x_col],\n",
        "                    y=datos[y_col],\n",
        "                    mode='lines',\n",
        "                    name='Tendencia',\n",
        "                    line=dict(dash='dash', color='red'),\n",
        "                    showlegend=False\n",
        "                ))\n",
        "\n",
        "            return fig\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _crear_heatmap(self, datos: pd.DataFrame) -> go.Figure:\n",
        "        \"\"\"Crea un mapa de calor para correlaciones\"\"\"\n",
        "        num_cols = datos.select_dtypes(include=['number']).columns\n",
        "\n",
        "        if len(num_cols) >= 3:\n",
        "            # Calcular matriz de correlaci√≥n\n",
        "            corr_matrix = datos[num_cols].corr()\n",
        "\n",
        "            fig = go.Figure(data=go.Heatmap(\n",
        "                z=corr_matrix.values,\n",
        "                x=corr_matrix.columns,\n",
        "                y=corr_matrix.columns,\n",
        "                colorscale='RdBu',\n",
        "                zmid=0,\n",
        "                text=corr_matrix.values.round(2),\n",
        "                texttemplate='%{text}',\n",
        "                textfont={\"size\": 10}\n",
        "            ))\n",
        "\n",
        "            fig.update_layout(\n",
        "                title='Matriz de Correlaci√≥n',\n",
        "                template='plotly_white',\n",
        "                height=600,\n",
        "                width=800\n",
        "            )\n",
        "\n",
        "            return fig\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _crear_barras_agrupadas(self, datos: pd.DataFrame) -> go.Figure:\n",
        "        \"\"\"Crea un gr√°fico de barras agrupadas para comparaciones\"\"\"\n",
        "        cat_cols = list(datos.select_dtypes(include=['object']).columns)\n",
        "        num_cols = list(datos.select_dtypes(include=['number']).columns)\n",
        "\n",
        "        if len(cat_cols) >= 1 and len(num_cols) >= 2:\n",
        "            x_col = cat_cols[0]\n",
        "\n",
        "            fig = go.Figure()\n",
        "\n",
        "            colors = px.colors.qualitative.Set3\n",
        "            for i, y_col in enumerate(num_cols[:4]):  # M√°ximo 4 series\n",
        "                fig.add_trace(go.Bar(\n",
        "                    name=y_col,\n",
        "                    x=datos[x_col],\n",
        "                    y=datos[y_col],\n",
        "                    marker_color=colors[i % len(colors)]\n",
        "                ))\n",
        "\n",
        "            fig.update_layout(\n",
        "                title=f'Comparaci√≥n de m√©tricas por {x_col}',\n",
        "                xaxis_title=x_col,\n",
        "                yaxis_title='Valores',\n",
        "                barmode='group',\n",
        "                template='plotly_white',\n",
        "                height=500\n",
        "            )\n",
        "\n",
        "            return fig\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _crear_visualizacion_automatica(self, datos: pd.DataFrame) -> go.Figure:\n",
        "        \"\"\"Crea una visualizaci√≥n autom√°tica como fallback\"\"\"\n",
        "        # Intentar diferentes tipos de visualizaci√≥n en orden\n",
        "        visualizaciones = [\n",
        "            self._crear_grafico_barras,\n",
        "            self._crear_grafico_lineas,\n",
        "            self._crear_grafico_pie,\n",
        "            self._crear_grafico_dispersion,\n",
        "            self._crear_heatmap\n",
        "        ]\n",
        "\n",
        "        for crear_viz in visualizaciones:\n",
        "            viz = crear_viz(datos)\n",
        "            if viz is not None:\n",
        "                return viz\n",
        "\n",
        "        # Si nada funciona, crear una tabla\n",
        "        return self._crear_tabla_visual(datos)\n",
        "\n",
        "    def _crear_tabla_visual(self, datos: pd.DataFrame) -> go.Figure:\n",
        "        \"\"\"Crea una tabla visual cuando otros gr√°ficos no son apropiados\"\"\"\n",
        "        # Limitar filas para visualizaci√≥n\n",
        "        datos_viz = datos.head(20)\n",
        "\n",
        "        fig = go.Figure(data=[go.Table(\n",
        "            header=dict(\n",
        "                values=list(datos_viz.columns),\n",
        "                fill_color='paleturquoise',\n",
        "                align='left'\n",
        "            ),\n",
        "            cells=dict(\n",
        "                values=[datos_viz[col] for col in datos_viz.columns],\n",
        "                fill_color='lavender',\n",
        "                align='left'\n",
        "            )\n",
        "        )])\n",
        "\n",
        "        fig.update_layout(\n",
        "            title='Tabla de Resultados',\n",
        "            height=500\n",
        "        )\n",
        "\n",
        "        return fig\n",
        "\n",
        "    def analizar_datos_inteligente(self, pregunta: str, datos: pd.DataFrame, interpretacion: Dict[str, Any]) -> str:\n",
        "        \"\"\"An√°lisis m√°s inteligente y contextualizado de los datos\"\"\"\n",
        "        if datos.empty:\n",
        "            return \"No hay datos para analizar. Verifica tu consulta.\"\n",
        "\n",
        "        # Crear contexto rico para el an√°lisis\n",
        "        contexto_analisis = {\n",
        "            'pregunta': pregunta,\n",
        "            'tipo_consulta': interpretacion['tipo_consulta'],\n",
        "            'num_filas': len(datos),\n",
        "            'columnas': list(datos.columns),\n",
        "            'tipos_datos': datos.dtypes.to_dict()\n",
        "        }\n",
        "\n",
        "        # Agregar estad√≠sticas relevantes\n",
        "        estadisticas = {}\n",
        "        for col in datos.select_dtypes(include=['number']).columns:\n",
        "            estadisticas[col] = {\n",
        "                'media': datos[col].mean(),\n",
        "                'mediana': datos[col].median(),\n",
        "                'min': datos[col].min(),\n",
        "                'max': datos[col].max(),\n",
        "                'std': datos[col].std()\n",
        "            }\n",
        "\n",
        "        contexto_analisis['estadisticas'] = estadisticas\n",
        "\n",
        "        # Preparar datos para el modelo\n",
        "        datos_str = datos.head(50).to_string()  # Limitar para no sobrecargar\n",
        "\n",
        "        prompt = f\"\"\"Analiza estos datos y proporciona insights valiosos.\n",
        "\n",
        "CONTEXTO:\n",
        "- Pregunta del usuario: {pregunta}\n",
        "- Tipo de consulta: {interpretacion['tipo_consulta']}\n",
        "- N√∫mero de resultados: {len(datos)}\n",
        "\n",
        "DATOS:\n",
        "{datos_str}\n",
        "\n",
        "ESTAD√çSTICAS:\n",
        "{json.dumps(estadisticas, indent=2, default=str)}\n",
        "\n",
        "INSTRUCCIONES:\n",
        "1. Responde directamente la pregunta del usuario\n",
        "2. Proporciona 2-3 insights clave basados en los datos\n",
        "3. Si hay patrones o anomal√≠as, menci√≥nalos\n",
        "4. Sugiere an√°lisis adicionales si son relevantes\n",
        "5. S√© conciso pero informativo\n",
        "\n",
        "FORMATO DE RESPUESTA:\n",
        "üìä **Respuesta directa:**\n",
        "[Respuesta a la pregunta]\n",
        "\n",
        "üîç **Insights clave:**\n",
        "‚Ä¢ [Insight 1]\n",
        "‚Ä¢ [Insight 2]\n",
        "‚Ä¢ [Insight 3 si aplica]\n",
        "\n",
        "üí° **Recomendaciones:**\n",
        "[Sugerencias de an√°lisis adicionales o acciones]\n",
        "\"\"\"\n",
        "\n",
        "        return self.consultar_ollama(prompt, MODELO_ANALISIS, TEMPERATURA_ANALISIS)\n",
        "\n",
        "    def cargar_datos(self, archivo) -> Tuple[str, List[str], str]:\n",
        "        \"\"\"Carga datos con an√°lisis mejorado\"\"\"\n",
        "        if not archivo:\n",
        "            return \"‚ùå No se seleccion√≥ archivo\", [], \"\"\n",
        "\n",
        "        # Leer archivo\n",
        "        df, mensaje = self.leer_archivo(archivo.name)\n",
        "        if df is None:\n",
        "            return mensaje, [], \"\"\n",
        "\n",
        "        # Procesar nombre de tabla\n",
        "        nombre_tabla = os.path.splitext(os.path.basename(archivo.name))[0]\n",
        "        nombre_tabla = re.sub(r'[^a-zA-Z0-9_]', '_', nombre_tabla)\n",
        "\n",
        "        try:\n",
        "            # Guardar en base de datos\n",
        "            df.to_sql(nombre_tabla, self.db, if_exists='replace', index=False)\n",
        "\n",
        "            # Detectar tipos de datos inteligentemente\n",
        "            tipos = self.detectar_tipos_inteligente(df)\n",
        "\n",
        "            # Crear informaci√≥n de tabla\n",
        "            info = {\n",
        "                'filas': len(df),\n",
        "                'columnas': list(df.columns),\n",
        "                'tipos': df.dtypes.to_dict(),\n",
        "                **tipos,\n",
        "                'muestra': df.head(5).to_dict()\n",
        "            }\n",
        "\n",
        "            self.tablas[nombre_tabla] = info\n",
        "\n",
        "            # Generar preguntas sugeridas\n",
        "            self.preguntas_sugeridas = self.generar_preguntas_inteligentes(info, nombre_tabla)\n",
        "            self.datos_cargados = True\n",
        "\n",
        "            # Crear resumen mejorado\n",
        "            resumen = self._crear_resumen_datos(nombre_tabla, df, info)\n",
        "\n",
        "            return f\"‚úÖ Datos cargados: {nombre_tabla} ({info['filas']:,} filas)\", self.preguntas_sugeridas, resumen\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"‚ùå Error: {str(e)}\", [], \"\"\n",
        "\n",
        "    def _crear_resumen_datos(self, nombre_tabla: str, df: pd.DataFrame, info: Dict) -> str:\n",
        "        \"\"\"Crea un resumen visual y informativo de los datos\"\"\"\n",
        "        resumen = f\"\"\"# üìä Resumen de Datos: {nombre_tabla}\n",
        "\n",
        "## üìà Informaci√≥n General\n",
        "- **Total de registros:** {info['filas']:,}\n",
        "- **Total de columnas:** {len(info['columnas'])}\n",
        "- **Tama√±o en memoria:** {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\n",
        "\n",
        "## üìã Tipos de Columnas\n",
        "\"\"\"\n",
        "\n",
        "        if info['numericas']:\n",
        "            resumen += f\"### üî¢ Num√©ricas ({len(info['numericas'])})\\n\"\n",
        "            for col in info['numericas'][:5]:\n",
        "                resumen += f\"- **{col}**: {df[col].dtype}\\n\"\n",
        "            if len(info['numericas']) > 5:\n",
        "                resumen += f\"- *... y {len(info['numericas']) - 5} m√°s*\\n\"\n",
        "\n",
        "        if info['categoricas']:\n",
        "            resumen += f\"\\n### üìù Categ√≥ricas ({len(info['categoricas'])})\\n\"\n",
        "            for col in info['categoricas'][:5]:\n",
        "                n_unique = df[col].nunique()\n",
        "                resumen += f\"- **{col}**: {n_unique} valores √∫nicos\\n\"\n",
        "            if len(info['categoricas']) > 5:\n",
        "                resumen += f\"- *... y {len(info['categoricas']) - 5} m√°s*\\n\"\n",
        "\n",
        "        if info['fechas']:\n",
        "            resumen += f\"\\n### üìÖ Fechas ({len(info['fechas'])})\\n\"\n",
        "            for col in info['fechas']:\n",
        "                min_fecha = df[col].min()\n",
        "                max_fecha = df[col].max()\n",
        "                resumen += f\"- **{col}**: desde {min_fecha} hasta {max_fecha}\\n\"\n",
        "\n",
        "        # Vista previa mejorada\n",
        "        resumen += f\"\\n## üëÄ Vista Previa\\n```\\n{df.head(5).to_string()}\\n```\"\n",
        "\n",
        "        # Estad√≠sticas r√°pidas\n",
        "        if info['numericas']:\n",
        "            resumen += f\"\\n## üìä Estad√≠sticas R√°pidas\\n\"\n",
        "            stats_df = df[info['numericas']].describe().round(2)\n",
        "            resumen += f\"```\\n{stats_df.to_string()}\\n```\"\n",
        "\n",
        "        return resumen\n",
        "\n",
        "    def obtener_contexto_detallado(self) -> str:\n",
        "        \"\"\"Genera contexto detallado para el LLM\"\"\"\n",
        "        if not self.tablas:\n",
        "            return \"No hay tablas cargadas en la base de datos.\"\n",
        "\n",
        "        contexto = \"ESQUEMA DE BASE DE DATOS:\\n\\n\"\n",
        "\n",
        "        for tabla, info in self.tablas.items():\n",
        "            contexto += f\"TABLA: {tabla}\\n\"\n",
        "            contexto += f\"Total filas: {info['filas']}\\n\\n\"\n",
        "            contexto += \"COLUMNAS:\\n\"\n",
        "\n",
        "            # Organizar columnas por tipo\n",
        "            for col in info['columnas']:\n",
        "                tipo = str(info['tipos'].get(col, 'unknown'))\n",
        "                categoria = \"otros\"\n",
        "\n",
        "                if col in info['numericas']:\n",
        "                    categoria = \"num√©rica\"\n",
        "                elif col in info['categoricas']:\n",
        "                    categoria = \"categ√≥rica\"\n",
        "                elif col in info['fechas']:\n",
        "                    categoria = \"fecha\"\n",
        "                elif col in info['booleanas']:\n",
        "                    categoria = \"booleana\"\n",
        "                elif col in info['ids']:\n",
        "                    categoria = \"identificador\"\n",
        "\n",
        "                contexto += f\"  - {col} ({categoria}, {tipo})\\n\"\n",
        "\n",
        "            contexto += \"\\n\"\n",
        "\n",
        "        return contexto\n",
        "\n",
        "    def procesar_consulta(self, pregunta: str) -> Tuple[str, str, Optional[go.Figure]]:\n",
        "        \"\"\"Procesa una consulta con interpretaci√≥n inteligente\"\"\"\n",
        "        if not self.datos_cargados:\n",
        "            return \"‚ö†Ô∏è Por favor carga datos primero\", \"\", None\n",
        "\n",
        "        # Verificar cach√©\n",
        "        if pregunta in self.cache_respuestas:\n",
        "            cached = self.cache_respuestas[pregunta]\n",
        "            return cached['respuesta'], cached['datos_html'], cached['grafico']\n",
        "\n",
        "        try:\n",
        "            # Interpretar la consulta\n",
        "            interpretacion = self.interpretar_consulta(pregunta)\n",
        "\n",
        "            # Generar SQL inteligente\n",
        "            sql = self.generar_sql_inteligente(pregunta, interpretacion)\n",
        "\n",
        "            # Ejecutar SQL\n",
        "            datos, estado = self.ejecutar_sql(sql)\n",
        "\n",
        "            # Si falla, intentar con LLM\n",
        "            if datos.empty and \"Error\" in estado:\n",
        "                sql = self.generar_sql_con_llm(pregunta)\n",
        "                datos, estado = self.ejecutar_sql(sql)\n",
        "\n",
        "            # Analizar resultados\n",
        "            analisis = self.analizar_datos_inteligente(pregunta, datos, interpretacion)\n",
        "\n",
        "            # Crear visualizaci√≥n\n",
        "            grafico = self.crear_visualizacion_inteligente(datos, interpretacion)\n",
        "\n",
        "            # Formatear respuesta\n",
        "            respuesta = f\"\"\"### ü§ñ Consulta SQL Generada:\n",
        "```sql\n",
        "{sql}\n",
        "```\n",
        "\n",
        "### üìä Estado: {estado}\n",
        "\n",
        "### üîç An√°lisis:\n",
        "{analisis}\n",
        "\"\"\"\n",
        "\n",
        "            # Crear HTML de datos\n",
        "            if not datos.empty:\n",
        "                datos_html = f\"\"\"\n",
        "<div style=\"max-height: 400px; overflow-y: auto;\">\n",
        "{datos.to_html(index=False, classes='dataframe', max_rows=100)}\n",
        "</div>\n",
        "\"\"\"\n",
        "            else:\n",
        "                datos_html = \"<p>No se obtuvieron datos</p>\"\n",
        "\n",
        "            # Guardar en cach√©\n",
        "            self.cache_respuestas[pregunta] = {\n",
        "                'respuesta': respuesta,\n",
        "                'datos_html': datos_html,\n",
        "                'grafico': grafico\n",
        "            }\n",
        "\n",
        "            # Agregar al historial\n",
        "            self.historial_consultas.append({\n",
        "                'pregunta': pregunta,\n",
        "                'sql': sql,\n",
        "                'resultado_filas': len(datos),\n",
        "                'timestamp': datetime.now()\n",
        "            })\n",
        "\n",
        "            return respuesta, datos_html, grafico\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"‚ùå Error procesando consulta: {str(e)}\"\n",
        "            return error_msg, \"\", None\n",
        "\n",
        "\n",
        "# 4. Inicializar sistema\n",
        "print(\"üöÄ Instalando componentes necesarios...\")\n",
        "instalar_ollama()\n",
        "genbi = GenBIMejorado()\n",
        "\n",
        "# 5. Funciones para Gradio mejoradas\n",
        "def chat_respuesta(pregunta: str, historial: List) -> Tuple[List, str, Any, str]:\n",
        "    \"\"\"Maneja las respuestas del chat\"\"\"\n",
        "    if not pregunta.strip():\n",
        "        return historial, \"\", None, \"\"\n",
        "\n",
        "    respuesta, datos_html, grafico = genbi.procesar_consulta(pregunta)\n",
        "    historial.append([pregunta, respuesta])\n",
        "\n",
        "    return historial, datos_html, grafico, \"\"\n",
        "\n",
        "def cargar_archivo(archivo) -> Tuple[str, str, gr.Dropdown, gr.Group]:\n",
        "    \"\"\"Carga el archivo y actualiza la interfaz\"\"\"\n",
        "    if archivo is None:\n",
        "        return \"‚ö†Ô∏è Selecciona un archivo\", \"\", gr.update(), gr.update(visible=False)\n",
        "\n",
        "    resultado, preguntas, resumen = genbi.cargar_datos(archivo)\n",
        "\n",
        "    return (\n",
        "        resultado,\n",
        "        resumen,\n",
        "        gr.update(choices=preguntas, value=None if not preguntas else preguntas[0]),\n",
        "        gr.update(visible=genbi.datos_cargados)\n",
        "    )\n",
        "\n",
        "def usar_pregunta_sugerida(pregunta_seleccionada: str) -> str:\n",
        "    \"\"\"Usa una pregunta sugerida\"\"\"\n",
        "    return pregunta_seleccionada if pregunta_seleccionada else \"\"\n",
        "\n",
        "def exportar_resultados(datos_html: str) -> str:\n",
        "    \"\"\"Exporta los resultados a CSV\"\"\"\n",
        "    if not datos_html or \"No se obtuvieron datos\" in datos_html:\n",
        "        return None\n",
        "\n",
        "    # Extraer tabla del HTML\n",
        "    try:\n",
        "        from io import StringIO\n",
        "        df = pd.read_html(StringIO(datos_html))[0]\n",
        "        csv = df.to_csv(index=False)\n",
        "        return csv\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# 6. Interfaz Gradio mejorada\n",
        "with gr.Blocks(\n",
        "    title=\"GenBI Inteligente\",\n",
        "    theme=gr.themes.Soft(),\n",
        "    css=\"\"\"\n",
        "    .gradio-container {\n",
        "        font-family: 'Inter', sans-serif;\n",
        "    }\n",
        "    .dataframe {\n",
        "        font-size: 12px;\n",
        "        width: 100%;\n",
        "    }\n",
        "    .gr-button-primary {\n",
        "        background-color: #2563eb !important;\n",
        "    }\n",
        "    .gr-button-primary:hover {\n",
        "        background-color: #1d4ed8 !important;\n",
        "    }\n",
        "    \"\"\"\n",
        ") as app:\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        # üß† GenBI Inteligente - An√°lisis de Datos con IA\n",
        "        ### Carga tus datos y hazle preguntas en lenguaje natural\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    with gr.Tab(\"üìÅ 1. Cargar Datos\", elem_id=\"datos-tab\"):\n",
        "        gr.Markdown(\n",
        "            \"\"\"\n",
        "            ### Paso 1: Selecciona tu archivo de datos\n",
        "            Formatos soportados: **CSV**, **Excel** (.xlsx, .xls), **JSON**\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                archivo_input = gr.File(\n",
        "                    label=\"Arrastra tu archivo aqu√≠ o haz clic para seleccionar\",\n",
        "                    file_types=[\".csv\", \".xlsx\", \".xls\", \".json\"],\n",
        "                    elem_id=\"file-upload\"\n",
        "                )\n",
        "                cargar_btn = gr.Button(\n",
        "                    \"üöÄ Cargar y Analizar\",\n",
        "                    variant=\"primary\",\n",
        "                    size=\"lg\",\n",
        "                    elem_id=\"load-btn\"\n",
        "                )\n",
        "                resultado_carga = gr.Textbox(\n",
        "                    label=\"Estado\",\n",
        "                    interactive=False,\n",
        "                    elem_id=\"status\"\n",
        "                )\n",
        "\n",
        "            with gr.Column(scale=2):\n",
        "                resumen_datos = gr.Markdown(\n",
        "                    \"### üìä Resumen de Datos\\n*Carga un archivo para ver el an√°lisis*\",\n",
        "                    elem_id=\"data-summary\"\n",
        "                )\n",
        "\n",
        "    with gr.Tab(\"üí¨ 2. Hacer Preguntas\", elem_id=\"chat-tab\"):\n",
        "        chat_disponible = gr.Markdown(\n",
        "            \"‚ö†Ô∏è **Primero carga datos en la pesta√±a anterior**\",\n",
        "            visible=True,\n",
        "            elem_id=\"chat-warning\"\n",
        "        )\n",
        "\n",
        "        with gr.Group(visible=False, elem_id=\"chat-interface\") as chat_group:\n",
        "            gr.Markdown(\"### üí° Preguntas Sugeridas\")\n",
        "\n",
        "            with gr.Row():\n",
        "                preguntas_dropdown = gr.Dropdown(\n",
        "                    choices=[],\n",
        "                    label=\"Selecciona una pregunta o escribe la tuya\",\n",
        "                    interactive=True,\n",
        "                    elem_id=\"suggested-questions\"\n",
        "                )\n",
        "                usar_sugerida_btn = gr.Button(\n",
        "                    \"üìù Usar\",\n",
        "                    size=\"sm\",\n",
        "                    elem_id=\"use-suggested\"\n",
        "                )\n",
        "\n",
        "            chatbot = gr.Chatbot(\n",
        "                label=\"Conversaci√≥n\",\n",
        "                height=400,\n",
        "                elem_id=\"chatbot\"\n",
        "            )\n",
        "\n",
        "            with gr.Row():\n",
        "                pregunta = gr.Textbox(\n",
        "                    label=\"Tu pregunta\",\n",
        "                    placeholder=\"Ej: ¬øCu√°l es el total de ventas por categor√≠a?\",\n",
        "                    scale=4,\n",
        "                    elem_id=\"question-input\"\n",
        "                )\n",
        "                enviar = gr.Button(\n",
        "                    \"üì§ Enviar\",\n",
        "                    scale=1,\n",
        "                    variant=\"primary\",\n",
        "                    elem_id=\"send-btn\"\n",
        "                )\n",
        "\n",
        "            with gr.Accordion(\"üìä Resultados Detallados\", open=True):\n",
        "                datos_display = gr.HTML(\n",
        "                    label=\"Datos\",\n",
        "                    elem_id=\"data-display\"\n",
        "                )\n",
        "                grafico_display = gr.Plot(\n",
        "                    label=\"Visualizaci√≥n\",\n",
        "                    elem_id=\"chart-display\"\n",
        "                )\n",
        "\n",
        "    with gr.Tab(\"üìö Ayuda\", elem_id=\"help-tab\"):\n",
        "        gr.Markdown(\n",
        "            \"\"\"\n",
        "            ## üéØ C√≥mo usar GenBI Inteligente\n",
        "\n",
        "            ### 1. **Carga tus datos**\n",
        "            - Soporta archivos CSV, Excel y JSON\n",
        "            - Los datos se analizan autom√°ticamente\n",
        "            - Se detectan tipos de columnas inteligentemente\n",
        "\n",
        "            ### 2. **Haz preguntas en lenguaje natural**\n",
        "            - \"¬øCu√°l es el total de ventas?\"\n",
        "            - \"Mu√©strame la evoluci√≥n mensual\"\n",
        "            - \"¬øCu√°les son los top 10 productos?\"\n",
        "            - \"Compara las ventas por regi√≥n\"\n",
        "\n",
        "            ### 3. **Tipos de an√°lisis soportados**\n",
        "            - üìä **Agregaciones**: suma, promedio, m√°ximo, m√≠nimo\n",
        "            - üìà **Tendencias**: evoluci√≥n temporal\n",
        "            - ü•á **Rankings**: top N elementos\n",
        "            - üìä **Distribuciones**: porcentajes y proporciones\n",
        "            - üîç **Comparaciones**: entre categor√≠as\n",
        "\n",
        "            ### üí° Tips\n",
        "            - Usa las preguntas sugeridas como punto de partida\n",
        "            - S√© espec√≠fico con los nombres de columnas\n",
        "            - Los gr√°ficos se generan autom√°ticamente\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "    # Eventos mejorados\n",
        "    cargar_btn.click(\n",
        "        cargar_archivo,\n",
        "        inputs=[archivo_input],\n",
        "        outputs=[resultado_carga, resumen_datos, preguntas_dropdown, chat_group]\n",
        "    )\n",
        "\n",
        "    usar_sugerida_btn.click(\n",
        "        usar_pregunta_sugerida,\n",
        "        inputs=[preguntas_dropdown],\n",
        "        outputs=[pregunta]\n",
        "    )\n",
        "\n",
        "    # Eventos de chat\n",
        "    enviar.click(\n",
        "        chat_respuesta,\n",
        "        inputs=[pregunta, chatbot],\n",
        "        outputs=[chatbot, datos_display, grafico_display, pregunta]\n",
        "    )\n",
        "\n",
        "    pregunta.submit(\n",
        "        chat_respuesta,\n",
        "        inputs=[pregunta, chatbot],\n",
        "        outputs=[chatbot, datos_display, grafico_display, pregunta]\n",
        "    )\n",
        "\n",
        "# 7. Lanzar aplicaci√≥n\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"‚ú® GenBI Inteligente est√° listo!\")\n",
        "    print(\"üåê Abriendo interfaz web...\")\n",
        "    app.launch(\n",
        "        share=True,\n",
        "        server_port=7860,\n",
        "        show_error=True\n",
        "    )"
      ]
    }
  ]
}